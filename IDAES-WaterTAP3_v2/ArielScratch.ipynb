{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tampa_bay\n",
      "------- Adding Unit Processes -------\n",
      "sw_onshore_intake\n",
      "sulfuric_acid_addition\n",
      "ferric_chloride_addition\n",
      "chlorination\n",
      "static_mixer\n",
      "tri_media_filtration\n",
      "cartridge_filtration\n",
      "ro_first_pass\n",
      "ro_second_pass\n",
      "lime_softening\n",
      "chlorination_b\n",
      "caustic_soda_addition\n",
      "ammonia_addition\n",
      "treated_storage\n",
      "21600.0\n",
      "backwash_solids_handling\n",
      "municipal_drinking\n",
      "surface_discharge\n",
      "-------------------------------------\n",
      "adding source\n",
      "adding splitter\n",
      "params into splitter --> [0.67, 0.33]\n",
      "----- Connecting Unit Processes -----\n",
      "seawater ToUnitName --> sw_onshore_intake\n",
      "sw_onshore_intake ToUnitName --> sulfuric_acid_addition\n",
      "sulfuric_acid_addition ToUnitName --> ferric_chloride_addition\n",
      "ferric_chloride_addition ToUnitName --> chlorination\n",
      "chlorination ToUnitName --> static_mixer\n",
      "tri_media_filtration ToUnitName --> cartridge_filtration\n",
      "tri_media_filtration ToUnitName --> backwash_solids_handling\n",
      "lime_softening ToUnitName --> chlorination_b\n",
      "chlorination_b ToUnitName --> caustic_soda_addition\n",
      "caustic_soda_addition ToUnitName --> ammonia_addition\n",
      "ammonia_addition ToUnitName --> treated_storage\n",
      "treated_storage ToUnitName --> municipal_drinking\n",
      "ro_second_pass ToUnitName --> mixer1\n",
      "mixer1 ToUnitName --> lime_softening\n",
      "cartridge_filtration ToUnitName --> mixer2\n",
      "ro_second_pass ToUnitName --> mixer2\n",
      "mixer2 ToUnitName --> ro_first_pass\n",
      "static_mixer ToUnitName --> mixer3\n",
      "backwash_solids_handling ToUnitName --> mixer3\n",
      "mixer3 ToUnitName --> tri_media_filtration\n",
      "splitter1 ToUnitName --> ro_second_pass\n",
      "splitter1 ToUnitName --> mixer1\n",
      "ro_first_pass ToUnitName --> splitter1\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import watertap as wt\n",
    "import pandas as pd\n",
    "from pyomo.environ import value, Block\n",
    "from idaes.core import FlowsheetBlock\n",
    "%matplotlib inline\n",
    "from pylab import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from case_study_trains import *\n",
    "import case_study_trains\n",
    "# import pyomo.util.infeasible as infeas\n",
    "# print(infeas.log_infeasible_bounds(m))\n",
    "# infeas.log_close_to_bounds(m)\n",
    "\n",
    "\n",
    "m = wt.watertap_setup(dynamic = False)\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"KBHDP\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"Irwin\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"EMWD\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"Santa_Barbara\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "wt.case_study_trains.train = {\"case_study\": \"tampa_bay\",\n",
    "                             \"reference\": \"nawi\",\n",
    "                             \"scenario\": \"baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"Ashkelon\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"Tampa_Bay\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"HRSD\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"Big_Spring\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"OCWD\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"Solaire\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "\n",
    "# TODO LATER: how to make this sync with info in train input data. We might not need to do that.\n",
    "#But, if the source water type is different to what is in the train (pfd dictionary), \n",
    "#then we should updat the node name. If more than two sources - what to do? Needs to be\n",
    "#based on pfd node!?\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"KBHDP\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"KBHDP_Brackish_Ave\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"Irwin\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"Brackish\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"EMWD\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"EMWD_CA_Brackish\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"Santa_Barbara\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"Seawater\"}\n",
    "\n",
    "wt.case_study_trains.source_water = {\"case_study\": \"tampa_bay\", \n",
    "                             \"reference\": \"nawi\",\n",
    "                             \"scenario\": \"baseline\",\n",
    "                             \"water_type\": \"seawater\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"Ashkelon\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"Seawater\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"Tampa_Bay\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"Seawater\"}\n",
    "# \n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"HRSD\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"HRSD_Municipal\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"Big_Spring\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"Big_Spring_Feed\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"OCWD\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"OCWD_Feed\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"Solaire\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": [\"Solaire_Graywater\", \"Solaire_Blackwater\", \"Solaire_Stormwater\"]}\n",
    "\n",
    "\n",
    "m = wt.case_study_trains.get_case_study(m=m) # flow is set as case study flow unless defined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500px\"\n",
       "            src=\"tmp/example.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fc141096650>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt.display.show_train2(model_name=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN MODEL with optimal ro so that the model solves. Then runs again with set pressure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unfixing feed presure and area for ro_first_pass\n",
      "unfixing feed presure and area for ro_second_pass\n",
      "degrees_of_freedom: 4\n",
      "WaterTAP3 solution optimal\n",
      "optimal ro area and pressures:\n",
      "ro_first_pass feed pressure 58.318339322344706\n",
      "ro_first_pass membrane area 149358.2181263329\n",
      "ro_second_pass feed pressure 89.99999847618598\n",
      "ro_second_pass membrane area 21305.55936746448\n",
      "setting feed presure for ro_first_pass to --> 85\n",
      "setting feed presure for ro_second_pass to --> 35\n",
      "degrees_of_freedom: 2\n",
      "WaterTAP3 solution optimal\n",
      "fs.sw_onshore_intake\n",
      "total_cap_investment: 10.216867778290633\n",
      "----------------------------------------------------------------------\n",
      "fs.sulfuric_acid_addition\n",
      "total_cap_investment: 0.23072715211599915\n",
      "----------------------------------------------------------------------\n",
      "fs.ferric_chloride_addition\n",
      "total_cap_investment: 2.9536394454284336\n",
      "----------------------------------------------------------------------\n",
      "fs.chlorination\n",
      "total_cap_investment: 9.265881440407075\n",
      "----------------------------------------------------------------------\n",
      "fs.static_mixer\n",
      "total_cap_investment: 0.1162155841035918\n",
      "----------------------------------------------------------------------\n",
      "fs.tri_media_filtration\n",
      "total_cap_investment: 8.067722349162832\n",
      "----------------------------------------------------------------------\n",
      "fs.cartridge_filtration\n",
      "total_cap_investment: 7.584516536765473\n",
      "----------------------------------------------------------------------\n",
      "fs.ro_first_pass\n",
      "total_cap_investment: 59.24728909295732\n",
      "----------------------------------------------------------------------\n",
      "fs.ro_second_pass\n",
      "total_cap_investment: 16.20852060818361\n",
      "----------------------------------------------------------------------\n",
      "fs.lime_softening\n",
      "total_cap_investment: 35.9024895921186\n",
      "----------------------------------------------------------------------\n",
      "fs.chlorination_b\n",
      "total_cap_investment: 8.219656116882394\n",
      "----------------------------------------------------------------------\n",
      "fs.caustic_soda_addition\n",
      "total_cap_investment: 1.5333100505027837\n",
      "----------------------------------------------------------------------\n",
      "fs.ammonia_addition\n",
      "total_cap_investment: 0.6617911795787459\n",
      "----------------------------------------------------------------------\n",
      "fs.treated_storage\n",
      "total_cap_investment: 9.295173054846638\n",
      "----------------------------------------------------------------------\n",
      "fs.backwash_solids_handling\n",
      "total_cap_investment: 6.2847052741837865\n",
      "----------------------------------------------------------------------\n",
      "fs.municipal_drinking\n",
      "total_cap_investment: 2.7419678375481342\n",
      "----------------------------------------------------------------------\n",
      "fs.surface_discharge\n",
      "total_cap_investment: 10.021055011700982\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------- System Level Metrics and Costs -------------------\n",
      "Total Capital Investment ($MM) 188.551528104777\n",
      "Annual Fixed Operating Cost ($MM/yr) 2.50246791354888\n",
      "Annual Catalysts and Chemicals Cost ($MM/yr) 3.5095812361586676\n",
      "Annual Electricity Costs ($MM/yr) 11.993223478160706\n",
      "Annual Other Variable Costs ($MM/yr) 1.0720179355210893\n",
      "Annual Operating Costs ($MM/yr) 19.07729056338934\n",
      "Treated water (m3/s) ---> 1.3167852920633207\n",
      "Total water recovery (%) ---> 68.30684954290342\n",
      "Electricity intensity (kwh/m3) --->  3.7753125970590435\n",
      "LCOW ($/m3) --->  0.8226483851709775\n",
      "Electricity portion of LCOW (%) ---> 35.1075160276393\n",
      "----------------------------------------------------------------------\n",
      "ro_first_pass feed pressure 85\n",
      "ro_first_pass membrane area 104453.71620390711\n",
      "ro_second_pass feed pressure 35\n",
      "ro_second_pass membrane area 74215.93971627444\n"
     ]
    }
   ],
   "source": [
    "# # RUN MODEL with optimal ro --> estimating area and pressure for optimal LCOW\n",
    "# so that the model solves and gets you results. Then runs again with set pressure.\n",
    "for key in m.fs.pfd_dict.keys():\n",
    "    if m.fs.pfd_dict[key][\"Unit\"] == \"reverse_osmosis\":\n",
    "        getattr(m.fs, key).feed.pressure.unfix()\n",
    "        getattr(m.fs, key).membrane_area.unfix()\n",
    "        print(\"unfixing feed presure and area for\", key)\n",
    "        \n",
    "wt.run_water_tap(m = m, objective=True)\n",
    "\n",
    "# prints RO results\n",
    "print(\"optimal ro area and pressures:\")\n",
    "for key in m.fs.pfd_dict.keys():\n",
    "    if m.fs.pfd_dict[key][\"Unit\"] == \"reverse_osmosis\":\n",
    "        print(key, \"feed pressure\", getattr(m.fs, key).feed.pressure[0]())\n",
    "        print(key, \"membrane area\", getattr(m.fs, key).membrane_area[0]())\n",
    "\n",
    "# RESET PRESSURE TO USER INPUT\n",
    "for key in m.fs.pfd_dict.keys():\n",
    "    if m.fs.pfd_dict[key][\"Unit\"] == \"reverse_osmosis\":\n",
    "        if \"feed_pressure\" in m.fs.pfd_dict[key][\"Parameter\"]:\n",
    "            if m.fs.pfd_dict[key][\"Parameter\"][\"type\"] == \"pass\":\n",
    "                getattr(m.fs, key).feed.pressure.fix(m.fs.pfd_dict[key][\"Parameter\"][\"feed_pressure\"])\n",
    "                print(\"setting feed presure for\", key, \"to -->\", m.fs.pfd_dict[key][\"Parameter\"][\"feed_pressure\"])\n",
    "\n",
    "wt.run_water_tap(m = m, objective=True, print_model_results=\"summary\")\n",
    "\n",
    "for key in m.fs.pfd_dict.keys():\n",
    "    if m.fs.pfd_dict[key][\"Unit\"] == \"reverse_osmosis\":\n",
    "        print(key, \"feed pressure\", getattr(m.fs, key).feed.pressure[0]())\n",
    "        print(key, \"membrane area\", getattr(m.fs, key).membrane_area[0]())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need the system recovery to match better.... set a maximum recovery rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyomo.environ import Constraint\n",
    "m.recovery_bound = Constraint(expr = m.fs.costing.system_recovery <= 0.55) # THIS IS FOR TAMPA BAY\n",
    "m.recovery_bound = Constraint(expr = m.fs.costing.system_recovery <= 0.50) # THIS IS FOR SANTA BARBARA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degrees_of_freedom: 2\n",
      "WaterTAP3 solution optimal\n",
      "fs.sw_onshore_intake\n",
      "total_cap_investment: 10.216867778290633\n",
      "----------------------------------------------------------------------\n",
      "fs.sulfuric_acid_addition\n",
      "total_cap_investment: 0.23072715211599915\n",
      "----------------------------------------------------------------------\n",
      "fs.ferric_chloride_addition\n",
      "total_cap_investment: 2.9536394454284336\n",
      "----------------------------------------------------------------------\n",
      "fs.chlorination\n",
      "total_cap_investment: 9.265881440407075\n",
      "----------------------------------------------------------------------\n",
      "fs.static_mixer\n",
      "total_cap_investment: 0.1162155841035918\n",
      "----------------------------------------------------------------------\n",
      "fs.tri_media_filtration\n",
      "total_cap_investment: 8.067722349162832\n",
      "----------------------------------------------------------------------\n",
      "fs.cartridge_filtration\n",
      "total_cap_investment: 7.584516536765473\n",
      "----------------------------------------------------------------------\n",
      "fs.ro_first_pass\n",
      "total_cap_investment: 56.74218435761429\n",
      "----------------------------------------------------------------------\n",
      "fs.ro_second_pass\n",
      "total_cap_investment: 12.901348101323569\n",
      "----------------------------------------------------------------------\n",
      "fs.lime_softening\n",
      "total_cap_investment: 30.646011852267907\n",
      "----------------------------------------------------------------------\n",
      "fs.chlorination_b\n",
      "total_cap_investment: 7.67736790604022\n",
      "----------------------------------------------------------------------\n",
      "fs.caustic_soda_addition\n",
      "total_cap_investment: 1.3407075836124847\n",
      "----------------------------------------------------------------------\n",
      "fs.ammonia_addition\n",
      "total_cap_investment: 0.6039757841837384\n",
      "----------------------------------------------------------------------\n",
      "fs.treated_storage\n",
      "total_cap_investment: 7.950910083570655\n",
      "----------------------------------------------------------------------\n",
      "fs.backwash_solids_handling\n",
      "total_cap_investment: 6.2847052741837865\n",
      "----------------------------------------------------------------------\n",
      "fs.municipal_drinking\n",
      "total_cap_investment: 2.272995813443232\n",
      "----------------------------------------------------------------------\n",
      "fs.surface_discharge\n",
      "total_cap_investment: 13.365277241992743\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "------------------- System Level Metrics and Costs -------------------\n",
      "Total Capital Investment ($MM) 178.2210542845066\n",
      "Annual Fixed Operating Cost ($MM/yr) 2.3655459340161595\n",
      "Annual Catalysts and Chemicals Cost ($MM/yr) 3.2752567733475275\n",
      "Annual Electricity Costs ($MM/yr) 9.918451373402672\n",
      "Annual Other Variable Costs ($MM/yr) 0.6976421987429182\n",
      "Annual Operating Costs ($MM/yr) 16.256896279509277\n",
      "Treated water (m3/s) ---> 1.0602625138581585\n",
      "Total water recovery (%) ---> 55.000000718877374\n",
      "Electricity intensity (kwh/m3) --->  3.877594756334364\n",
      "LCOW ($/m3) --->  0.9126145566374667\n",
      "Electricity portion of LCOW (%) ---> 32.50397407121532\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "wt.run_water_tap(m = m, objective=True, print_model_results=\"summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOULD SAVE PRESSURE AND AREA FOR RO!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates csv in results folder with the name: *case_study*_*scenario*.csv\n",
    "df = wt.get_results_table(m = m, case_study = \"santa_barbara\", scenario = \"baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls results/case_studies/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensitivity analyses\n",
    "changing_variables:\n",
    "onstream_factor\n",
    "electricity_price\n",
    "on_stream_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyomo.util.infeasible as infeas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infeas.log_infeasible_bounds(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "infeas.log_close_to_bounds(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def it_gets_results(appended, print_it=False, write_it=True):    \n",
    "    train = wt.case_study_trains.train\n",
    "\n",
    "    py_var = [\n",
    "        \"fixed_cap_inv\",\n",
    "        \"total_cap_investment\",\n",
    "        \"cat_and_chem_cost\",\n",
    "        \"electricity_cost\",\n",
    "        \"total_fixed_op_cost\",\n",
    "    \"flow_in\", \"flow_out\"]\n",
    "\n",
    "    excel_var = ['Fixed Capital Investment (FCI)',\n",
    "                'Total Capital Investment (TCI)',\n",
    "                'Catalysts and Chemicals',\n",
    "                'Electricity',\n",
    "                'Total Fixed Operating Costs']\n",
    "\n",
    "    case_study = train['case_study']\n",
    "    if print_it:\n",
    "        print(f'\\n######### Case study = {case_study} #########\\n\\n\\n')\n",
    "\n",
    "    cap_inv_tot = []\n",
    "\n",
    "    big_dict = {}\n",
    "\n",
    "    for b_unit in m.fs.component_objects(Block, descend_into=True):\n",
    "        unit = str(b_unit)[3:]\n",
    "        if hasattr(b_unit, 'costing'):\n",
    "            if print_it:\n",
    "                print(f'____________{unit}____________')\n",
    "            py_vals =  []\n",
    "            excel_vals = []\n",
    "            big_dict[unit] = {'python': {}, 'excel': {}}\n",
    "            df = pd.read_csv(\"data/case_study_results.csv\")\n",
    "            df = df[df.case_study == train['case_study']]\n",
    "            df = df[df.scenario == train['scenario']]\n",
    "            df = df[df.unit_process == unit]\n",
    "            flow_in_excel = round(df[df.variable == \"flow_vol_in\"].value.sum(), 5)\n",
    "            flow_out_excel = round(df[df.variable == 'flow_vol_out'].value.sum(), 5)\n",
    "            flow_in_python = round(value(b_unit.inlet.flow_vol[0.0] * 3600), 5)\n",
    "            flow_out_python = round(value(b_unit.outlet.flow_vol[0.0] * 3600), 5)\n",
    "            waste_python = round(value(b_unit.waste.flow_vol[0.0] * 3600), 5)\n",
    "            if print_it:\n",
    "                print(f'\\n#### flow_in\\nPython --> {flow_in_python}')\n",
    "                print(f'Excel --> {flow_in_excel}\\n\\n')\n",
    "                print(f'#### flow out\\nPython --> {flow_out_python}')\n",
    "                print(f'Excel --> {flow_out_excel}\\n\\n')\n",
    "                print(f'#### waste\\nPython--> {waste_python}\\n')\n",
    "            for py, ex in dict(zip(py_var, excel_var)).items():\n",
    "                if print_it:\n",
    "                    print(f'\\n#### {py}')\n",
    "                try:\n",
    "                    num = value(getattr(b_unit.costing, py))\n",
    "                    py_vals.append(num)\n",
    "                    if print_it:\n",
    "                        print(f'Python --> {round(num, 5)}')\n",
    "                except ZeroDivisionError:\n",
    "                    if print_it:\n",
    "                        print(f'Python --> {0} - ERROR')\n",
    "                    py_vals.append(0)\n",
    "\n",
    "                df = pd.read_csv(\"data/case_study_results.csv\")\n",
    "                df = df[df.case_study == train['case_study']]\n",
    "                df = df[df.scenario == train['scenario']]\n",
    "                df = df[df.unit_process == unit]\n",
    "                num = df[df.Variable == ex].value.sum()\n",
    "                if print_it:\n",
    "                    print(f'Excel --> {round(num, 5)}\\n\\n')\n",
    "                excel_vals.append(num)\n",
    "            py_vals.append(flow_in_python)\n",
    "            py_vals.append(flow_out_python)\n",
    "            py_dict = dict(zip(py_var, py_vals))\n",
    "            excel_vals.append(flow_in_excel)\n",
    "            excel_vals.append(flow_out_excel)\n",
    "            excel_dict = dict(zip(py_var, excel_vals))\n",
    "            big_dict[unit]['python'] = py_dict\n",
    "            big_dict[unit]['excel'] = excel_dict\n",
    "\n",
    "    else:\n",
    "        pass \n",
    "\n",
    "    df = pd.DataFrame.from_dict({(i,j): big_dict[i][j] \n",
    "                               for i in big_dict.keys() \n",
    "                               for j in big_dict[i].keys()},\n",
    "                               orient='index')\n",
    "\n",
    "    df['case_study'] = case_study\n",
    "    df['LCOW'] = value(m.fs.costing.LCOW)\n",
    "    if write_it:\n",
    "        df.to_csv(f'results/test_compare_{case_study}_{appended}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wt.run_water_tap(m=m, solver_results=True, print_model_results=True)\n",
    "# it_gets_results('testy1')\n",
    "# wt.run_water_tap(m=m, solver_results=True, print_model_results=False)\n",
    "# it_gets_results('testy2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_it_all(append1, append2, solver_results=True, model_results=False):\n",
    "    case_studies = ['Ashkelon', 'Big_Spring', 'Carlsbad', 'EMWD', 'HRSD', 'Irwin', 'KBHDP', 'OCWD', 'Santa_Barbara', 'Solaire', 'Tampa_Bay']\n",
    "    water_sources = ['Seawater', 'Big_Spring_Feed', 'Seawater', 'EMWD_CA_Brackish', 'HRSD_Municipal', 'Brackish', 'KBHDP_Brackish_Ave', 'OCWD_Feed', 'Seawater', 'Solaire_Graywater', 'Seawater']\n",
    "    wt_dict = dict(zip(case_studies, water_sources))\n",
    "    for k, v in wt_dict.items():\n",
    "        \n",
    "        m = wt.watertap_setup(dynamic = False)\n",
    "        \n",
    "        wt.case_study_trains.train = {\"case_study\": k,\n",
    "                                 \"reference\": \"NAWI\",\n",
    "                                 \"scenario\": \"Baseline\"}\n",
    "        \n",
    "        wt.case_study_trains.source_water = {\"case_study\": k, \n",
    "                                 \"reference\": \"NAWI\",\n",
    "                                 \"scenario\": \"Baseline\",\n",
    "                                 \"water_type\": v}\n",
    "        \n",
    "        wt.run_water_tap(m=m, solver_results=solver_results, print_model_results=model_results)\n",
    "        \n",
    "        it_gets_results(append1)\n",
    "        \n",
    "        wt.run_water_tap(m=m, solver_results=solver_results, print_model_results=model_results)\n",
    "        \n",
    "        it_gets_results(append2)\n",
    "# value(m.fs.costing.LCOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wt.run_water_tap(m=m, solver_results=True, print_model_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(f'results/test_compare_{case_study}.csv')\n",
    "wt.run_water_tap(m=m, solver_results=True, print_model_results=False)\n",
    "\n",
    "train = wt.case_study_trains.train\n",
    "\n",
    "py_var = [\n",
    "    \"fixed_cap_inv\",\n",
    "    \"total_cap_investment\",\n",
    "    \"cat_and_chem_cost\",\n",
    "    \"electricity_cost\",\n",
    "    \"total_fixed_op_cost\",\n",
    "\"flow_in\", \"flow_out\"]\n",
    "\n",
    "excel_var = ['Fixed Capital Investment (FCI)',\n",
    "            'Total Capital Investment (TCI)',\n",
    "            'Catalysts and Chemicals',\n",
    "            'Electricity',\n",
    "            'Total Fixed Operating Costs']\n",
    "\n",
    "case_study = train['case_study']\n",
    "print(f'\\n######### Case study = {case_study} #########\\n\\n\\n')\n",
    "\n",
    "cap_inv_tot = []\n",
    "\n",
    "big_dict = {}\n",
    "\n",
    "for b_unit in m.fs.component_objects(Block, descend_into=True):\n",
    "    unit = str(b_unit)[3:]\n",
    "    if hasattr(b_unit, 'costing'):\n",
    "        print(f'____________{unit}____________')\n",
    "        py_vals =  []\n",
    "        excel_vals = []\n",
    "        big_dict[unit] = {'python': {}, 'excel': {}}\n",
    "        df = pd.read_csv(\"data/case_study_results.csv\")\n",
    "        df = df[df.case_study == train['case_study']]\n",
    "        df = df[df.scenario == train['scenario']]\n",
    "        df = df[df.unit_process == unit]\n",
    "        flow_in_excel = round(df[df.variable == \"flow_vol_in\"].value.sum(), 5)\n",
    "        flow_out_excel = round(df[df.variable == 'flow_vol_out'].value.sum(), 5)\n",
    "        flow_in_python = round(value(b_unit.inlet.flow_vol[0.0] * 3600), 5)\n",
    "        flow_out_python = round(value(b_unit.outlet.flow_vol[0.0] * 3600), 5)\n",
    "        waste_python = round(value(b_unit.waste.flow_vol[0.0] * 3600), 5)\n",
    "        print(f'\\n#### flow_in\\nPython --> {flow_in_python}')\n",
    "        print(f'Excel --> {flow_in_excel}\\n\\n')\n",
    "        print(f'#### flow out\\nPython --> {flow_out_python}')\n",
    "        print(f'Excel --> {flow_out_excel}\\n\\n')\n",
    "        print(f'#### waste\\nPython--> {waste_python}\\n')\n",
    "        for py, ex in dict(zip(py_var, excel_var)).items():\n",
    "            print(f'\\n#### {py}')\n",
    "            try:\n",
    "                num = value(getattr(b_unit.costing, py))\n",
    "                py_vals.append(num)\n",
    "                print(f'Python --> {round(num, 5)}')\n",
    "            except ZeroDivisionError:\n",
    "                print(f'Python --> {0} - ERROR')\n",
    "                py_vals.append(0)\n",
    "            \n",
    "            df = pd.read_csv(\"data/case_study_results.csv\")\n",
    "            df = df[df.case_study == train['case_study']]\n",
    "            df = df[df.scenario == train['scenario']]\n",
    "            df = df[df.unit_process == unit]\n",
    "            num = df[df.Variable == ex].value.sum()\n",
    "            print(f'Excel --> {round(num, 5)}\\n\\n')\n",
    "            excel_vals.append(num)\n",
    "        py_vals.append(flow_in_python)\n",
    "        py_vals.append(flow_out_python)\n",
    "        py_dict = dict(zip(py_var, py_vals))\n",
    "        excel_vals.append(flow_in_excel)\n",
    "        excel_vals.append(flow_out_excel)\n",
    "        excel_dict = dict(zip(py_var, excel_vals))\n",
    "        big_dict[unit]['python'] = py_dict\n",
    "        big_dict[unit]['excel'] = excel_dict\n",
    "        \n",
    "else:\n",
    "    pass \n",
    "\n",
    "df = pd.DataFrame.from_dict({(i,j): big_dict[i][j] \n",
    "                           for i in big_dict.keys() \n",
    "                           for j in big_dict[i].keys()},\n",
    "                           orient='index')\n",
    "\n",
    "df['case_study'] = case_study\n",
    "df['LCOW'] = value(m.fs.costing.LCOW)\n",
    "df.to_csv(f'results/test_compare_{case_study}_new2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value(m.fs.costing.LCOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value(m.fs.coag_and_floc.water_recovery[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'results/test_compare_{case_study}_new1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_final = pd.DataFrame()\n",
    "# for case_name in [\"Ashkelon\", \"Carlsbad\", \"Tampa_Bay\"]: #, \"Santa_Barbra\"]: #, \"Ashkelon\"]:\n",
    "\n",
    "#     m = wt.watertap_setup(dynamic = False)\n",
    "\n",
    "#     wt.case_study_trains.train = {\"case_study\": case_name,\n",
    "#                                  \"reference\": \"NAWI\",\n",
    "#                                  \"scenario\": \"Baseline\"}\n",
    "\n",
    "#     # TODO LATER: how to make this sync with info in train input data. We might not need to do that.\n",
    "#     #But, if the source water type is different to what is in the train (pfd dictionary), \n",
    "#     #then we should updat the node name. If more than two sources - what to do? Needs to be\n",
    "#     #based on pfd node!?\n",
    "\n",
    "#     wt.case_study_trains.source_water = {\"case_study\": case_name, \n",
    "#                                  \"reference\": \"NAWI\",\n",
    "#                                  \"scenario\": \"Baseline\",\n",
    "#                                  \"water_type\": \"Seawater\"}\n",
    "    \n",
    "#     m = wt.case_study_trains.get_case_study(m = m) # flow is set as case study flow unless defined.\n",
    "    \n",
    "      \n",
    "#     wt.run_water_tap(m = m, solver_results = False, print_model_results = False)\n",
    "#     print(value(m.fs.costing.LCOW))\n",
    "#     df = get_results_table()\n",
    "#     df[\"case_study\"] = case_name\n",
    "#     df_final = pd.concat([df_final,df])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_table():\n",
    "\n",
    "    train = wt.case_study_trains.train\n",
    "\n",
    "    py_var = [\n",
    "        \"fixed_cap_inv\",\n",
    "        \"total_cap_investment\",\n",
    "        \"cat_and_chem_cost\",\n",
    "        \"electricity_cost\",\n",
    "        \"total_fixed_op_cost\"]\n",
    "\n",
    "    excel_var = ['Fixed Capital Investment (FCI)',\n",
    "                'Total Capital Investment (TCI)',\n",
    "                'Catalysts and Chemicals',\n",
    "                'Electricity',\n",
    "                'Total Fixed Operating Costs']\n",
    "    big_dict = {}\n",
    "    # for letter in ['A', 'B', 'C']:\n",
    "    for b_unit in m.fs.component_objects(Block, descend_into=True):\n",
    "        unit = str(b_unit)[3:]\n",
    "        if hasattr(b_unit, 'costing'):\n",
    "            #print(f'____________{unit}____________')\n",
    "            py_vals =  []\n",
    "            excel_vals = []\n",
    "            big_dict[unit] = {'python': {}, 'excel': {}}\n",
    "            for py, ex in dict(zip(py_var, excel_var)).items():\n",
    "                #print(f'\\n#### {py}')\n",
    "                try:\n",
    "                    num = value(getattr(b_unit.costing, py))\n",
    "                    py_vals.append(num)\n",
    "                    #print(f'Python --> {num}')\n",
    "                except ZeroDivisionError:\n",
    "                    #print(f'Python --> {0} - ERROR')\n",
    "                    py_vals.append(0)\n",
    "                py_dict = dict(zip(py_var, py_vals))\n",
    "                df = pd.read_csv(\"data/case_study_results.csv\")\n",
    "                df = df[df.case_study == train['case_study']]\n",
    "                df = df[df.scenario == train['scenario']]\n",
    "                df = df[df.unit_process == unit]\n",
    "                num = df[df.Variable == ex].value.max()\n",
    "                #print(f'Excel --> {num}\\n\\n')\n",
    "                excel_vals.append(num)\n",
    "                excel_dict = dict(zip(py_var, excel_vals))\n",
    "            big_dict[unit]['python'] = py_dict\n",
    "            big_dict[unit]['excel'] = excel_dict\n",
    "    else:\n",
    "        pass \n",
    "\n",
    "\n",
    "\n",
    "    df = pd.DataFrame.from_dict({(i,j): big_dict[i][j] \n",
    "                               for i in big_dict.keys() \n",
    "                               for j in big_dict[i].keys()},\n",
    "                           orient='index')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = case_study_trains.train \n",
    "source_water = case_study_trains.source_water \n",
    "source_or_use = None\n",
    "# getting the list of consituents with removal factors that are bigger than 0\n",
    "df1 = pd.read_csv(\"data/constituent_removal.csv\")\n",
    "df1 = df1[df1.reference == train[\"reference\"]]\n",
    "df1 = df1[df1.case_study == train[\"case_study\"]]\n",
    "df1 = df1[df1.scenario == train[\"scenario\"]]\n",
    "\n",
    "list1 = df1[df1.value >=0].constituent.unique()\n",
    "\n",
    "import importfile\n",
    "\n",
    "# grabs inlet water information\n",
    "# df = importfile.feedwater(\n",
    "#     input_file=\"data/case_study_water_sources.csv\",\n",
    "#     reference = source_water[\"reference\"], \n",
    "#     water_type = source_water[\"water_type\"], \n",
    "#     case_study = source_water[\"case_study\"],\n",
    "#     scenario = source_water[\"scenario\"])\n",
    "\n",
    "df2 = pd.read_csv('data/case_study_water_sources.csv', index_col='variable')\n",
    "df2 = df2[df2.reference == source_water['reference']]\n",
    "df2 = df2[df2.water_type == source_water['water_type']]\n",
    "df2 = df2[df2.case_study == source_water['case_study']]\n",
    "# df = df[df.source_or_use == source_water['source_or_use']]\n",
    "df2 = df2[df2.scenario == source_water['scenario']]\n",
    "df2 = df2.set_index(df2.index)\n",
    "df2['feedwater'] = df2.value\n",
    "df2['SourceNodeName'] = 'source_node'\n",
    "# gets list of consituents in inlet water\n",
    "list2 = df2.index\n",
    "\n",
    "# # combines list\n",
    "final_list = [x for x in list1 if x in list2]\n",
    "print(f'list1 = {list1}')\n",
    "print(f'list2 = {list2}')\n",
    "print(f'final_list = {final_list}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import case_study_trains\n",
    "unit_process = 'ro_deep'\n",
    "train = case_study_trains.train \n",
    "source_water = case_study_trains.source_water \n",
    "\n",
    "df = pd.read_csv(\"data/constituent_removal.csv\")\n",
    "df.case_study = np.where(df.case_study == \"Default\", train[\"case_study\"], df.case_study)\n",
    "df = df[df.reference == train[\"reference\"]]\n",
    "df = df[df.case_study == train[\"case_study\"]]\n",
    "df = df[df.scenario == train[\"scenario\"]]\n",
    "df = df[df.unit_process == unit_process]\n",
    "\n",
    "removal_dict = {}\n",
    "for constituent in df.constituent.unique():\n",
    "    removal_dict[constituent] = df[df.constituent == constituent].value.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removal_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generate_constituent_list\n",
    "df = pd.read_csv(\"data/water_recovery.csv\")\n",
    "case_study_name = case_study_trains.train[\"case_study\"]\n",
    "unit_process_type = 'microfiltration'\n",
    "unit_process_name = unit_process_type\n",
    "if unit_process_type == \"reverse_osmosis\": unit_process_type = \"ro_deep\"\n",
    "\n",
    "if case_study_name in df[df.unit_process == unit_process_type].case_study:\n",
    "    if \"calculated\" not in df[((df.unit_process == unit_process_type) & (df.case_study == case_study_name))].recovery.max():\n",
    "        flow_recovery_factor = float(df[((df.unit_process == unit_process_type) & (df.case_study == case_study_name))].recovery)\n",
    "        print(f'A = {flow_recovery_factor}\\n')\n",
    "        getattr(m.fs, unit_process_name).water_recovery.fix(flow_recovery_factor)\n",
    "else:\n",
    "    if \"calculated\" not in df[((df.unit_process == unit_process_type) & (df.case_study == \"Default\"))].recovery.max():\n",
    "        flow_recovery_factor = float(df[((df.unit_process == unit_process_type) & (df.case_study == \"Default\"))].recovery)\n",
    "        print(f'B = {flow_recovery_factor}\\n')\n",
    "        getattr(m.fs, unit_process_name).water_recovery.fix(flow_recovery_factor)\n",
    "\n",
    "# Get constituent list and removal rates for this unit process\n",
    "train_constituent_removal_factors = generate_constituent_list.get_removal_factors(unit_process_type)\n",
    "\n",
    "for constituent_name in getattr(m.fs, unit_process_name).config.property_package.component_list:\n",
    "    print(constituent_name)\n",
    "\n",
    "    if constituent_name in train_constituent_removal_factors.keys():\n",
    "        getattr(m.fs, unit_process_name).removal_fraction[:, constituent_name].fix(train_constituent_removal_factors[constituent_name])\n",
    "    else:\n",
    "        getattr(m.fs, unit_process_name).removal_fraction[:, constituent_name].fix(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value(m.fs.microfiltration.water_recovery[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_constituent_removal_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fs.microfiltration.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.unit_process == unit_process_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cost_range_list = []; #results will be inputted in this array\n",
    "#up_name = \"tri_media_filtration\" # which unit process it applies to. TODO hould be user input.\n",
    "\n",
    "#for value_change in pct_to_target1: # cycles through each value from MC range\n",
    "for value_change in [0.4, 0.8]: #, 0.9]:\n",
    "\n",
    "    # create and build model\n",
    "    m = wt.watertap_setup(dynamic = False)\n",
    "    m = wt.case_study_trains.get_case_study(name = 'carlsbad', flow = 4.5833, m = m)\n",
    "\n",
    "    m.fs.tri_media_filtration.water_recovery.fix(value_change)\n",
    "\n",
    "    # set variable to MC value\n",
    "    wt.run_water_tap(m)\n",
    "    results_table = get_results_table(m, unit_process_name)\n",
    "    cost_range_list.append(results_table.total_up_cost.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_range_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DO NOT USE THE BELOW ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "\n",
    "mu = 0.6\n",
    "sigma = .1\n",
    "num_reps = 50\n",
    "\n",
    "input_list = np.random.normal(mu,sigma, size = num_reps) #, sigma, num_reps).round(4)\n",
    "\n",
    "count, bins, ignored = plt.hist(input_list, 25, density=True)\n",
    "plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) * np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
    "          linewidth=2, color='r')\n",
    "plt.show()\n",
    "\n",
    "### INPUT TO MODEL LIST: ### CAN BE AUTOMATED FOR USER TO LABEL THE VARIABLE. TOOD ###\n",
    "no_of_proc = 4\n",
    "list_final = []\n",
    "for i in range(no_of_proc):\n",
    "    part2 = len(input_list) / no_of_proc\n",
    "    i2 = ((i+1)*part2)\n",
    "    list1 = input_list[int(i*part2):int(i2)]\n",
    "    list_final.append(list1)\n",
    "    \n",
    "    \n",
    "def monte_run(list_final):\n",
    "    print('goes in')\n",
    "\n",
    "    up_name = \"tri_media_filtration\" # which unit process it applies to. TODO hould be user input.\n",
    "    cost_range_list = []; #results will be inputted in this array\n",
    "\n",
    "    #for value_change in pct_to_target1: # cycles through each value from MC range\n",
    "    for value_change in list_final:\n",
    "\n",
    "        # create and build model\n",
    "        m = wt.watertap_setup(dynamic = False)\n",
    "        m = wt.case_study_trains.get_case_study(name = 'carlsbad', flow = 4.5833, m = m)\n",
    "\n",
    "        getattr(m.fs, up_name).water_recovery.fix(value_change)\n",
    "\n",
    "        # set variable to MC value\n",
    "        result = wt.run_water_tap(m)\n",
    "        results_table = get_results_table(m, unit_process_names)\n",
    "        cost_range_list.append(results_table.total_up_cost.sum())\n",
    "\n",
    "\n",
    "    return cost_range_list\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "pool=Pool()\n",
    "dfs = pool.map(monte_run, list_final) #SomeClass().preprocess_data()\n",
    "\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####TO DO LOAD AND SAVE!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SAVE TRAIN ####\n",
    "# path = 'trains/Tutorial1_treatment_train_example.csv'\n",
    "# wt.save_train(T, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### LOAD TRAIN ####\n",
    "# path = 'trains/Tutorial1_treatment_train_example.csv'\n",
    "# TT = wt.load_train(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wt.display.show_train(TT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
