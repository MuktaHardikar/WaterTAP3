{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solaire\n",
      "------- Adding Unit Processes -------\n",
      "gray_and_black_tank\n",
      "stormwater_tank\n",
      "treated_storage\n",
      "water_pumping_station\n",
      "mbr_nitrification\n",
      "uv_aop\n",
      "ozone_aop\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "reduction operation 'argmin' not allowed for this dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7f2a054241c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    121\u001b[0m                              \"water_type\": [\"Solaire_Graywater\", \"Solaire_Blackwater\", \"Solaire_Stormwater\"]}\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcase_study_trains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_case_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# flow is set as case study flow unless defined.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/NAWI/WaterTap/NAWI-WaterTAP3/IDAES-WaterTAP3_v2/case_study_trains.py\u001b[0m in \u001b[0;36mget_case_study\u001b[0;34m(flow, m)\u001b[0m\n\u001b[1;32m     85\u001b[0m         m = wt.design.add_unit_process(m = m, \n\u001b[1;32m     86\u001b[0m                                        \u001b[0munit_process_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                                        unit_process_type = pfd_dict[key]['Unit'])\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NAWI/WaterTap/NAWI-WaterTAP3/IDAES-WaterTAP3_v2/design.py\u001b[0m in \u001b[0;36madd_unit_process\u001b[0;34m(m, unit_process_name, unit_process_type, with_connection, from_splitter, splitter_tream, link_to, link_from, connection_type, stream_name)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m### SET PARAMS HERE FOR UP ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# PARAMS =\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_process_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_costing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinancials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwith_connection\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NAWI/WaterTap/NAWI-WaterTAP3/IDAES-WaterTAP3_v2/ozone_aop.py\u001b[0m in \u001b[0;36mget_costing\u001b[0;34m(self, module, cost_method, year, unit_params)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mtups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdose_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'flow_mgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cost'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dose'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dose'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mozone_consumption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0midx_dose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0midx_dose\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tap-idaes3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36midxmin\u001b[0;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2072\u001b[0m         \"\"\"\n\u001b[1;32m   2073\u001b[0m         \u001b[0mskipna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_argmin_with_skipna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2074\u001b[0;31m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnanops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanargmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2075\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2076\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tap-idaes3/lib/python3.7/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mf_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nan\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 raise TypeError(\n\u001b[0;32m---> 67\u001b[0;31m                     \u001b[0;34mf\"reduction operation '{f_name}' not allowed for this dtype\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 )\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: reduction operation 'argmin' not allowed for this dtype"
     ]
    }
   ],
   "source": [
    "import watertap as wt\n",
    "import pandas as pd\n",
    "from pyomo.environ import value, Block\n",
    "from idaes.core import FlowsheetBlock\n",
    "%matplotlib inline\n",
    "from pylab import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from case_study_trains import *\n",
    "import case_study_trains\n",
    "# import pyomo.util.infeasible as infeas\n",
    "# print(infeas.log_infeasible_bounds(m))\n",
    "# infeas.log_close_to_bounds(m)\n",
    "\n",
    "\n",
    "m = wt.watertap_setup(dynamic = False)\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"KBHDP\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"Irwin\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"EMWD\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"Santa_Barbara\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"Carlsbad\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"Ashkelon\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"Tampa_Bay\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"HRSD\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"Big_Spring\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"OCWD\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "wt.case_study_trains.train = {\"case_study\": \"Solaire\",\n",
    "                             \"reference\": \"NAWI\",\n",
    "                             \"scenario\": \"Baseline\"}\n",
    "\n",
    "\n",
    "# TODO LATER: how to make this sync with info in train input data. We might not need to do that.\n",
    "#But, if the source water type is different to what is in the train (pfd dictionary), \n",
    "#then we should updat the node name. If more than two sources - what to do? Needs to be\n",
    "#based on pfd node!?\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"KBHDP\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"KBHDP_Brackish_Ave\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"Irwin\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"Brackish\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"EMWD\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"EMWD_CA_Brackish\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"Santa_Barbara\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"Seawater\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"Carlsbad\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"Seawater\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"Ashkelon\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"Seawater\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"Tampa_Bay\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"Seawater\"}\n",
    "# \n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"HRSD\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"HRSD_Municipal\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"Big_Spring\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"Big_Spring_Feed\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"OCWD\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"OCWD_Feed\"}\n",
    "\n",
    "wt.case_study_trains.source_water = {\"case_study\": \"Solaire\", \n",
    "                             \"reference\": \"NAWI\",\n",
    "                             \"scenario\": \"Baseline\",\n",
    "                             \"water_type\": [\"Solaire_Graywater\", \"Solaire_Blackwater\", \"Solaire_Stormwater\"]}\n",
    "\n",
    "m = wt.case_study_trains.get_case_study(m=m) # flow is set as case study flow unless defined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt.display.show_train2(model_name=m)\n",
    "# m.fs.pfd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wt.run_water_tap(m = m, solver_results = False, print_model_results = True, objective=False, \n",
    "                 max_attemps = 1) #, initialize_flow = )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#wt.run_water_tap(m=m, solver_results=True, print_model_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.fs.reverse_osmosis.feed.pressure.unfix()\n",
    "#m.fs.ro_deep.pmax.unfix()\n",
    "#m.fs.reverse_osmosis.membrane_area.unfix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.fs.Solaire_Graywater.flow_vol_in.fix(8.89E-04)\n",
    "# m.fs.Solaire_Blackwater.flow_vol_in.fix(2.22E-04)\n",
    "# m.fs.Solaire_Stormwater.flow_vol_in.fix(5.56E-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyomo.util.infeasible as infeas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "infeas.log_infeasible_bounds(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: fs.sw_onshore_intake.flow_vol_in[0.0] near LB of 1e-08\n",
      "INFO: fs.sw_onshore_intake.flow_vol_out[0.0] near LB of 0\n",
      "INFO: fs.sw_onshore_intake.flow_vol_waste[0.0] near LB of 0\n",
      "INFO: fs.ferric_chloride_addition.flow_vol_in[0.0] near LB of 1e-08\n",
      "INFO: fs.ferric_chloride_addition.flow_vol_out[0.0] near LB of 0\n",
      "INFO: fs.ferric_chloride_addition.flow_vol_waste[0.0] near LB of 0\n",
      "INFO: fs.chlorination.flow_vol_in[0.0] near LB of 1e-08\n",
      "INFO: fs.chlorination.flow_vol_out[0.0] near LB of 0\n",
      "INFO: fs.chlorination.flow_vol_waste[0.0] near LB of 0\n",
      "INFO: fs.static_mixer.flow_vol_in[0.0] near LB of 1e-08\n",
      "INFO: fs.static_mixer.flow_vol_out[0.0] near LB of 0\n",
      "INFO: fs.static_mixer.flow_vol_waste[0.0] near LB of 0\n",
      "INFO: fs.treated_storage.flow_vol_in[0.0] near LB of 1e-08\n",
      "INFO: fs.treated_storage.flow_vol_out[0.0] near LB of 0\n",
      "INFO: fs.treated_storage.flow_vol_waste[0.0] near LB of 0\n",
      "INFO: fs.tri_media_filtration.flow_vol_in[0.0] near LB of 1e-08\n",
      "INFO: fs.tri_media_filtration.flow_vol_out[0.0] near LB of 0\n",
      "INFO: fs.tri_media_filtration.flow_vol_waste[0.0] near LB of 0\n",
      "INFO: fs.municipal_drinking.flow_vol_in[0.0] near LB of 1e-08\n",
      "INFO: fs.municipal_drinking.flow_vol_out[0.0] near LB of 0\n",
      "INFO: fs.municipal_drinking.flow_vol_waste[0.0] near LB of 0\n"
     ]
    }
   ],
   "source": [
    "infeas.log_close_to_bounds(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_ScalarFlowsheetBlock' object has no attribute 'coag_and_floc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9b3825820ac9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoag_and_floc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_cap_investment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3.4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tap-idaes3/lib/python3.7/site-packages/pyomo/core/base/block.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;31m# throw the \"normal\" AttributeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         raise AttributeError(\"'%s' object has no attribute '%s'\"\n\u001b[0;32m--> 524\u001b[0;31m                              % (self.__class__.__name__, val))\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_ScalarFlowsheetBlock' object has no attribute 'coag_and_floc'"
     ]
    }
   ],
   "source": [
    "m.fs.coag_and_floc.costing.total_cap_investment()/3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'holding_tank': {'Unit': 'holding_tank',\n",
       "  'Type': 'intake',\n",
       "  'ToUnitName': 'microfiltration',\n",
       "  'FromPort': 'outlet',\n",
       "  'Parameter': {'source_type': ['Big_Spring_Feed'],\n",
       "   'avg_storage_time': 0.25,\n",
       "   'surge_cap': 0},\n",
       "  'Unnamed: 9': nan,\n",
       "  'Unnamed: 10': nan,\n",
       "  'Unnamed: 11': nan,\n",
       "  'Unnamed: 12': nan,\n",
       "  'Unnamed: 13': nan},\n",
       " 'microfiltration': {'Unit': 'basic_unit',\n",
       "  'Type': 'treatment',\n",
       "  'ToUnitName': ['reverse_osmosis', 'uv_aop'],\n",
       "  'FromPort': ['outlet', 'outlet'],\n",
       "  'Parameter': {'unit_process_name': 'microfiltration',\n",
       "   'split_fraction': [0.4, 0.6]},\n",
       "  'Unnamed: 9': nan,\n",
       "  'Unnamed: 10': nan,\n",
       "  'Unnamed: 11': nan,\n",
       "  'Unnamed: 12': nan,\n",
       "  'Unnamed: 13': nan},\n",
       " 'reverse_osmosis': {'Unit': 'reverse_osmosis',\n",
       "  'Type': 'treatment',\n",
       "  'ToUnitName': 'uv_aop',\n",
       "  'FromPort': 'outlet',\n",
       "  'Parameter': {'pass': 'first', 'membrane_area': 50000, 'feed_pressure': 65},\n",
       "  'Unnamed: 9': nan,\n",
       "  'Unnamed: 10': nan,\n",
       "  'Unnamed: 11': nan,\n",
       "  'Unnamed: 12': nan,\n",
       "  'Unnamed: 13': nan},\n",
       " 'uv_aop': {'Unit': 'uv_aop',\n",
       "  'Type': 'treatment',\n",
       "  'ToUnitName': 'treated_storage',\n",
       "  'FromPort': 'outlet',\n",
       "  'Parameter': {'chemical_name': ['Hydrogen_Peroxide'],\n",
       "   'dose': 5,\n",
       "   'uv_dose': 100,\n",
       "   'aop': True},\n",
       "  'Unnamed: 9': nan,\n",
       "  'Unnamed: 10': nan,\n",
       "  'Unnamed: 11': nan,\n",
       "  'Unnamed: 12': nan,\n",
       "  'Unnamed: 13': nan},\n",
       " 'treated_storage': {'Unit': 'holding_tank',\n",
       "  'Type': 'treatment',\n",
       "  'ToUnitName': 'municipal_drinking',\n",
       "  'FromPort': 'outlet',\n",
       "  'Parameter': {'avg_storage_time': 0.25, 'surge_cap': 1e-07},\n",
       "  'Unnamed: 9': nan,\n",
       "  'Unnamed: 10': nan,\n",
       "  'Unnamed: 11': nan,\n",
       "  'Unnamed: 12': nan,\n",
       "  'Unnamed: 13': nan},\n",
       " 'municipal_drinking': {'Unit': 'municipal_drinking',\n",
       "  'Type': 'use',\n",
       "  'ToUnitName': nan,\n",
       "  'FromPort': nan,\n",
       "  'Parameter': nan,\n",
       "  'Unnamed: 9': nan,\n",
       "  'Unnamed: 10': nan,\n",
       "  'Unnamed: 11': nan,\n",
       "  'Unnamed: 12': nan,\n",
       "  'Unnamed: 13': nan},\n",
       " 'surface_discharge': {'Unit': 'surface_discharge',\n",
       "  'Type': 'waste',\n",
       "  'ToUnitName': nan,\n",
       "  'FromPort': nan,\n",
       "  'Parameter': nan,\n",
       "  'Unnamed: 9': nan,\n",
       "  'Unnamed: 10': nan,\n",
       "  'Unnamed: 11': nan,\n",
       "  'Unnamed: 12': nan,\n",
       "  'Unnamed: 13': nan}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fs.pfd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def it_gets_results(appended, print_it=False, write_it=True):    \n",
    "    train = wt.case_study_trains.train\n",
    "\n",
    "    py_var = [\n",
    "        \"fixed_cap_inv\",\n",
    "        \"total_cap_investment\",\n",
    "        \"cat_and_chem_cost\",\n",
    "        \"electricity_cost\",\n",
    "        \"total_fixed_op_cost\",\n",
    "    \"flow_in\", \"flow_out\"]\n",
    "\n",
    "    excel_var = ['Fixed Capital Investment (FCI)',\n",
    "                'Total Capital Investment (TCI)',\n",
    "                'Catalysts and Chemicals',\n",
    "                'Electricity',\n",
    "                'Total Fixed Operating Costs']\n",
    "\n",
    "    case_study = train['case_study']\n",
    "    if print_it:\n",
    "        print(f'\\n######### Case study = {case_study} #########\\n\\n\\n')\n",
    "\n",
    "    cap_inv_tot = []\n",
    "\n",
    "    big_dict = {}\n",
    "\n",
    "    for b_unit in m.fs.component_objects(Block, descend_into=True):\n",
    "        unit = str(b_unit)[3:]\n",
    "        if hasattr(b_unit, 'costing'):\n",
    "            if print_it:\n",
    "                print(f'____________{unit}____________')\n",
    "            py_vals =  []\n",
    "            excel_vals = []\n",
    "            big_dict[unit] = {'python': {}, 'excel': {}}\n",
    "            df = pd.read_csv(\"data/case_study_results.csv\")\n",
    "            df = df[df.case_study == train['case_study']]\n",
    "            df = df[df.scenario == train['scenario']]\n",
    "            df = df[df.unit_process == unit]\n",
    "            flow_in_excel = round(df[df.variable == \"flow_vol_in\"].value.sum(), 5)\n",
    "            flow_out_excel = round(df[df.variable == 'flow_vol_out'].value.sum(), 5)\n",
    "            flow_in_python = round(value(b_unit.inlet.flow_vol[0.0] * 3600), 5)\n",
    "            flow_out_python = round(value(b_unit.outlet.flow_vol[0.0] * 3600), 5)\n",
    "            waste_python = round(value(b_unit.waste.flow_vol[0.0] * 3600), 5)\n",
    "            if print_it:\n",
    "                print(f'\\n#### flow_in\\nPython --> {flow_in_python}')\n",
    "                print(f'Excel --> {flow_in_excel}\\n\\n')\n",
    "                print(f'#### flow out\\nPython --> {flow_out_python}')\n",
    "                print(f'Excel --> {flow_out_excel}\\n\\n')\n",
    "                print(f'#### waste\\nPython--> {waste_python}\\n')\n",
    "            for py, ex in dict(zip(py_var, excel_var)).items():\n",
    "                if print_it:\n",
    "                    print(f'\\n#### {py}')\n",
    "                try:\n",
    "                    num = value(getattr(b_unit.costing, py))\n",
    "                    py_vals.append(num)\n",
    "                    if print_it:\n",
    "                        print(f'Python --> {round(num, 5)}')\n",
    "                except ZeroDivisionError:\n",
    "                    if print_it:\n",
    "                        print(f'Python --> {0} - ERROR')\n",
    "                    py_vals.append(0)\n",
    "\n",
    "                df = pd.read_csv(\"data/case_study_results.csv\")\n",
    "                df = df[df.case_study == train['case_study']]\n",
    "                df = df[df.scenario == train['scenario']]\n",
    "                df = df[df.unit_process == unit]\n",
    "                num = df[df.Variable == ex].value.sum()\n",
    "                if print_it:\n",
    "                    print(f'Excel --> {round(num, 5)}\\n\\n')\n",
    "                excel_vals.append(num)\n",
    "            py_vals.append(flow_in_python)\n",
    "            py_vals.append(flow_out_python)\n",
    "            py_dict = dict(zip(py_var, py_vals))\n",
    "            excel_vals.append(flow_in_excel)\n",
    "            excel_vals.append(flow_out_excel)\n",
    "            excel_dict = dict(zip(py_var, excel_vals))\n",
    "            big_dict[unit]['python'] = py_dict\n",
    "            big_dict[unit]['excel'] = excel_dict\n",
    "\n",
    "    else:\n",
    "        pass \n",
    "\n",
    "    df = pd.DataFrame.from_dict({(i,j): big_dict[i][j] \n",
    "                               for i in big_dict.keys() \n",
    "                               for j in big_dict[i].keys()},\n",
    "                               orient='index')\n",
    "\n",
    "    df['case_study'] = case_study\n",
    "    df['LCOW'] = value(m.fs.costing.LCOW)\n",
    "    if write_it:\n",
    "        df.to_csv(f'results/test_compare_{case_study}_{appended}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wt.run_water_tap(m=m, solver_results=True, print_model_results=True)\n",
    "# it_gets_results('testy1')\n",
    "# wt.run_water_tap(m=m, solver_results=True, print_model_results=False)\n",
    "# it_gets_results('testy2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_it_all(append1, append2, solver_results=True, model_results=False):\n",
    "    case_studies = ['Ashkelon', 'Big_Spring', 'Carlsbad', 'EMWD', 'HRSD', 'Irwin', 'KBHDP', 'OCWD', 'Santa_Barbara', 'Solaire', 'Tampa_Bay']\n",
    "    water_sources = ['Seawater', 'Big_Spring_Feed', 'Seawater', 'EMWD_CA_Brackish', 'HRSD_Municipal', 'Brackish', 'KBHDP_Brackish_Ave', 'OCWD_Feed', 'Seawater', 'Solaire_Graywater', 'Seawater']\n",
    "    wt_dict = dict(zip(case_studies, water_sources))\n",
    "    for k, v in wt_dict.items():\n",
    "        \n",
    "        m = wt.watertap_setup(dynamic = False)\n",
    "        \n",
    "        wt.case_study_trains.train = {\"case_study\": k,\n",
    "                                 \"reference\": \"NAWI\",\n",
    "                                 \"scenario\": \"Baseline\"}\n",
    "        \n",
    "        wt.case_study_trains.source_water = {\"case_study\": k, \n",
    "                                 \"reference\": \"NAWI\",\n",
    "                                 \"scenario\": \"Baseline\",\n",
    "                                 \"water_type\": v}\n",
    "        \n",
    "        wt.run_water_tap(m=m, solver_results=solver_results, print_model_results=model_results)\n",
    "        \n",
    "        it_gets_results(append1)\n",
    "        \n",
    "        wt.run_water_tap(m=m, solver_results=solver_results, print_model_results=model_results)\n",
    "        \n",
    "        it_gets_results(append2)\n",
    "# value(m.fs.costing.LCOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wt.run_water_tap(m=m, solver_results=True, print_model_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(f'results/test_compare_{case_study}.csv')\n",
    "wt.run_water_tap(m=m, solver_results=True, print_model_results=False)\n",
    "\n",
    "train = wt.case_study_trains.train\n",
    "\n",
    "py_var = [\n",
    "    \"fixed_cap_inv\",\n",
    "    \"total_cap_investment\",\n",
    "    \"cat_and_chem_cost\",\n",
    "    \"electricity_cost\",\n",
    "    \"total_fixed_op_cost\",\n",
    "\"flow_in\", \"flow_out\"]\n",
    "\n",
    "excel_var = ['Fixed Capital Investment (FCI)',\n",
    "            'Total Capital Investment (TCI)',\n",
    "            'Catalysts and Chemicals',\n",
    "            'Electricity',\n",
    "            'Total Fixed Operating Costs']\n",
    "\n",
    "case_study = train['case_study']\n",
    "print(f'\\n######### Case study = {case_study} #########\\n\\n\\n')\n",
    "\n",
    "cap_inv_tot = []\n",
    "\n",
    "big_dict = {}\n",
    "\n",
    "for b_unit in m.fs.component_objects(Block, descend_into=True):\n",
    "    unit = str(b_unit)[3:]\n",
    "    if hasattr(b_unit, 'costing'):\n",
    "        print(f'____________{unit}____________')\n",
    "        py_vals =  []\n",
    "        excel_vals = []\n",
    "        big_dict[unit] = {'python': {}, 'excel': {}}\n",
    "        df = pd.read_csv(\"data/case_study_results.csv\")\n",
    "        df = df[df.case_study == train['case_study']]\n",
    "        df = df[df.scenario == train['scenario']]\n",
    "        df = df[df.unit_process == unit]\n",
    "        flow_in_excel = round(df[df.variable == \"flow_vol_in\"].value.sum(), 5)\n",
    "        flow_out_excel = round(df[df.variable == 'flow_vol_out'].value.sum(), 5)\n",
    "        flow_in_python = round(value(b_unit.inlet.flow_vol[0.0] * 3600), 5)\n",
    "        flow_out_python = round(value(b_unit.outlet.flow_vol[0.0] * 3600), 5)\n",
    "        waste_python = round(value(b_unit.waste.flow_vol[0.0] * 3600), 5)\n",
    "        print(f'\\n#### flow_in\\nPython --> {flow_in_python}')\n",
    "        print(f'Excel --> {flow_in_excel}\\n\\n')\n",
    "        print(f'#### flow out\\nPython --> {flow_out_python}')\n",
    "        print(f'Excel --> {flow_out_excel}\\n\\n')\n",
    "        print(f'#### waste\\nPython--> {waste_python}\\n')\n",
    "        for py, ex in dict(zip(py_var, excel_var)).items():\n",
    "            print(f'\\n#### {py}')\n",
    "            try:\n",
    "                num = value(getattr(b_unit.costing, py))\n",
    "                py_vals.append(num)\n",
    "                print(f'Python --> {round(num, 5)}')\n",
    "            except ZeroDivisionError:\n",
    "                print(f'Python --> {0} - ERROR')\n",
    "                py_vals.append(0)\n",
    "            \n",
    "            df = pd.read_csv(\"data/case_study_results.csv\")\n",
    "            df = df[df.case_study == train['case_study']]\n",
    "            df = df[df.scenario == train['scenario']]\n",
    "            df = df[df.unit_process == unit]\n",
    "            num = df[df.Variable == ex].value.sum()\n",
    "            print(f'Excel --> {round(num, 5)}\\n\\n')\n",
    "            excel_vals.append(num)\n",
    "        py_vals.append(flow_in_python)\n",
    "        py_vals.append(flow_out_python)\n",
    "        py_dict = dict(zip(py_var, py_vals))\n",
    "        excel_vals.append(flow_in_excel)\n",
    "        excel_vals.append(flow_out_excel)\n",
    "        excel_dict = dict(zip(py_var, excel_vals))\n",
    "        big_dict[unit]['python'] = py_dict\n",
    "        big_dict[unit]['excel'] = excel_dict\n",
    "        \n",
    "else:\n",
    "    pass \n",
    "\n",
    "df = pd.DataFrame.from_dict({(i,j): big_dict[i][j] \n",
    "                           for i in big_dict.keys() \n",
    "                           for j in big_dict[i].keys()},\n",
    "                           orient='index')\n",
    "\n",
    "df['case_study'] = case_study\n",
    "df['LCOW'] = value(m.fs.costing.LCOW)\n",
    "df.to_csv(f'results/test_compare_{case_study}_new2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value(m.fs.costing.LCOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value(m.fs.coag_and_floc.water_recovery[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'results/test_compare_{case_study}_new1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_final = pd.DataFrame()\n",
    "# for case_name in [\"Ashkelon\", \"Carlsbad\", \"Tampa_Bay\"]: #, \"Santa_Barbra\"]: #, \"Ashkelon\"]:\n",
    "\n",
    "#     m = wt.watertap_setup(dynamic = False)\n",
    "\n",
    "#     wt.case_study_trains.train = {\"case_study\": case_name,\n",
    "#                                  \"reference\": \"NAWI\",\n",
    "#                                  \"scenario\": \"Baseline\"}\n",
    "\n",
    "#     # TODO LATER: how to make this sync with info in train input data. We might not need to do that.\n",
    "#     #But, if the source water type is different to what is in the train (pfd dictionary), \n",
    "#     #then we should updat the node name. If more than two sources - what to do? Needs to be\n",
    "#     #based on pfd node!?\n",
    "\n",
    "#     wt.case_study_trains.source_water = {\"case_study\": case_name, \n",
    "#                                  \"reference\": \"NAWI\",\n",
    "#                                  \"scenario\": \"Baseline\",\n",
    "#                                  \"water_type\": \"Seawater\"}\n",
    "    \n",
    "#     m = wt.case_study_trains.get_case_study(m = m) # flow is set as case study flow unless defined.\n",
    "    \n",
    "      \n",
    "#     wt.run_water_tap(m = m, solver_results = False, print_model_results = False)\n",
    "#     print(value(m.fs.costing.LCOW))\n",
    "#     df = get_results_table()\n",
    "#     df[\"case_study\"] = case_name\n",
    "#     df_final = pd.concat([df_final,df])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_table():\n",
    "\n",
    "    train = wt.case_study_trains.train\n",
    "\n",
    "    py_var = [\n",
    "        \"fixed_cap_inv\",\n",
    "        \"total_cap_investment\",\n",
    "        \"cat_and_chem_cost\",\n",
    "        \"electricity_cost\",\n",
    "        \"total_fixed_op_cost\"]\n",
    "\n",
    "    excel_var = ['Fixed Capital Investment (FCI)',\n",
    "                'Total Capital Investment (TCI)',\n",
    "                'Catalysts and Chemicals',\n",
    "                'Electricity',\n",
    "                'Total Fixed Operating Costs']\n",
    "    big_dict = {}\n",
    "    # for letter in ['A', 'B', 'C']:\n",
    "    for b_unit in m.fs.component_objects(Block, descend_into=True):\n",
    "        unit = str(b_unit)[3:]\n",
    "        if hasattr(b_unit, 'costing'):\n",
    "            #print(f'____________{unit}____________')\n",
    "            py_vals =  []\n",
    "            excel_vals = []\n",
    "            big_dict[unit] = {'python': {}, 'excel': {}}\n",
    "            for py, ex in dict(zip(py_var, excel_var)).items():\n",
    "                #print(f'\\n#### {py}')\n",
    "                try:\n",
    "                    num = value(getattr(b_unit.costing, py))\n",
    "                    py_vals.append(num)\n",
    "                    #print(f'Python --> {num}')\n",
    "                except ZeroDivisionError:\n",
    "                    #print(f'Python --> {0} - ERROR')\n",
    "                    py_vals.append(0)\n",
    "                py_dict = dict(zip(py_var, py_vals))\n",
    "                df = pd.read_csv(\"data/case_study_results.csv\")\n",
    "                df = df[df.case_study == train['case_study']]\n",
    "                df = df[df.scenario == train['scenario']]\n",
    "                df = df[df.unit_process == unit]\n",
    "                num = df[df.Variable == ex].value.max()\n",
    "                #print(f'Excel --> {num}\\n\\n')\n",
    "                excel_vals.append(num)\n",
    "                excel_dict = dict(zip(py_var, excel_vals))\n",
    "            big_dict[unit]['python'] = py_dict\n",
    "            big_dict[unit]['excel'] = excel_dict\n",
    "    else:\n",
    "        pass \n",
    "\n",
    "\n",
    "\n",
    "    df = pd.DataFrame.from_dict({(i,j): big_dict[i][j] \n",
    "                               for i in big_dict.keys() \n",
    "                               for j in big_dict[i].keys()},\n",
    "                           orient='index')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = case_study_trains.train \n",
    "source_water = case_study_trains.source_water \n",
    "source_or_use = None\n",
    "# getting the list of consituents with removal factors that are bigger than 0\n",
    "df1 = pd.read_csv(\"data/constituent_removal.csv\")\n",
    "df1 = df1[df1.reference == train[\"reference\"]]\n",
    "df1 = df1[df1.case_study == train[\"case_study\"]]\n",
    "df1 = df1[df1.scenario == train[\"scenario\"]]\n",
    "\n",
    "list1 = df1[df1.value >=0].constituent.unique()\n",
    "\n",
    "import importfile\n",
    "\n",
    "# grabs inlet water information\n",
    "# df = importfile.feedwater(\n",
    "#     input_file=\"data/case_study_water_sources.csv\",\n",
    "#     reference = source_water[\"reference\"], \n",
    "#     water_type = source_water[\"water_type\"], \n",
    "#     case_study = source_water[\"case_study\"],\n",
    "#     scenario = source_water[\"scenario\"])\n",
    "\n",
    "df2 = pd.read_csv('data/case_study_water_sources.csv', index_col='variable')\n",
    "df2 = df2[df2.reference == source_water['reference']]\n",
    "df2 = df2[df2.water_type == source_water['water_type']]\n",
    "df2 = df2[df2.case_study == source_water['case_study']]\n",
    "# df = df[df.source_or_use == source_water['source_or_use']]\n",
    "df2 = df2[df2.scenario == source_water['scenario']]\n",
    "df2 = df2.set_index(df2.index)\n",
    "df2['feedwater'] = df2.value\n",
    "df2['SourceNodeName'] = 'source_node'\n",
    "# gets list of consituents in inlet water\n",
    "list2 = df2.index\n",
    "\n",
    "# # combines list\n",
    "final_list = [x for x in list1 if x in list2]\n",
    "print(f'list1 = {list1}')\n",
    "print(f'list2 = {list2}')\n",
    "print(f'final_list = {final_list}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import case_study_trains\n",
    "unit_process = 'ro_deep'\n",
    "train = case_study_trains.train \n",
    "source_water = case_study_trains.source_water \n",
    "\n",
    "df = pd.read_csv(\"data/constituent_removal.csv\")\n",
    "df.case_study = np.where(df.case_study == \"Default\", train[\"case_study\"], df.case_study)\n",
    "df = df[df.reference == train[\"reference\"]]\n",
    "df = df[df.case_study == train[\"case_study\"]]\n",
    "df = df[df.scenario == train[\"scenario\"]]\n",
    "df = df[df.unit_process == unit_process]\n",
    "\n",
    "removal_dict = {}\n",
    "for constituent in df.constituent.unique():\n",
    "    removal_dict[constituent] = df[df.constituent == constituent].value.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removal_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generate_constituent_list\n",
    "df = pd.read_csv(\"data/water_recovery.csv\")\n",
    "case_study_name = case_study_trains.train[\"case_study\"]\n",
    "unit_process_type = 'microfiltration'\n",
    "unit_process_name = unit_process_type\n",
    "if unit_process_type == \"reverse_osmosis\": unit_process_type = \"ro_deep\"\n",
    "\n",
    "if case_study_name in df[df.unit_process == unit_process_type].case_study:\n",
    "    if \"calculated\" not in df[((df.unit_process == unit_process_type) & (df.case_study == case_study_name))].recovery.max():\n",
    "        flow_recovery_factor = float(df[((df.unit_process == unit_process_type) & (df.case_study == case_study_name))].recovery)\n",
    "        print(f'A = {flow_recovery_factor}\\n')\n",
    "        getattr(m.fs, unit_process_name).water_recovery.fix(flow_recovery_factor)\n",
    "else:\n",
    "    if \"calculated\" not in df[((df.unit_process == unit_process_type) & (df.case_study == \"Default\"))].recovery.max():\n",
    "        flow_recovery_factor = float(df[((df.unit_process == unit_process_type) & (df.case_study == \"Default\"))].recovery)\n",
    "        print(f'B = {flow_recovery_factor}\\n')\n",
    "        getattr(m.fs, unit_process_name).water_recovery.fix(flow_recovery_factor)\n",
    "\n",
    "# Get constituent list and removal rates for this unit process\n",
    "train_constituent_removal_factors = generate_constituent_list.get_removal_factors(unit_process_type)\n",
    "\n",
    "for constituent_name in getattr(m.fs, unit_process_name).config.property_package.component_list:\n",
    "    print(constituent_name)\n",
    "\n",
    "    if constituent_name in train_constituent_removal_factors.keys():\n",
    "        getattr(m.fs, unit_process_name).removal_fraction[:, constituent_name].fix(train_constituent_removal_factors[constituent_name])\n",
    "    else:\n",
    "        getattr(m.fs, unit_process_name).removal_fraction[:, constituent_name].fix(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value(m.fs.microfiltration.water_recovery[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_constituent_removal_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fs.microfiltration.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.unit_process == unit_process_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cost_range_list = []; #results will be inputted in this array\n",
    "#up_name = \"tri_media_filtration\" # which unit process it applies to. TODO hould be user input.\n",
    "\n",
    "#for value_change in pct_to_target1: # cycles through each value from MC range\n",
    "for value_change in [0.4, 0.8]: #, 0.9]:\n",
    "\n",
    "    # create and build model\n",
    "    m = wt.watertap_setup(dynamic = False)\n",
    "    m = wt.case_study_trains.get_case_study(name = 'carlsbad', flow = 4.5833, m = m)\n",
    "\n",
    "    m.fs.tri_media_filtration.water_recovery.fix(value_change)\n",
    "\n",
    "    # set variable to MC value\n",
    "    wt.run_water_tap(m)\n",
    "    results_table = get_results_table(m, unit_process_name)\n",
    "    cost_range_list.append(results_table.total_up_cost.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_range_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DO NOT USE THE BELOW ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "\n",
    "mu = 0.6\n",
    "sigma = .1\n",
    "num_reps = 50\n",
    "\n",
    "input_list = np.random.normal(mu,sigma, size = num_reps) #, sigma, num_reps).round(4)\n",
    "\n",
    "count, bins, ignored = plt.hist(input_list, 25, density=True)\n",
    "plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) * np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
    "          linewidth=2, color='r')\n",
    "plt.show()\n",
    "\n",
    "### INPUT TO MODEL LIST: ### CAN BE AUTOMATED FOR USER TO LABEL THE VARIABLE. TOOD ###\n",
    "no_of_proc = 4\n",
    "list_final = []\n",
    "for i in range(no_of_proc):\n",
    "    part2 = len(input_list) / no_of_proc\n",
    "    i2 = ((i+1)*part2)\n",
    "    list1 = input_list[int(i*part2):int(i2)]\n",
    "    list_final.append(list1)\n",
    "    \n",
    "    \n",
    "def monte_run(list_final):\n",
    "    print('goes in')\n",
    "\n",
    "    up_name = \"tri_media_filtration\" # which unit process it applies to. TODO hould be user input.\n",
    "    cost_range_list = []; #results will be inputted in this array\n",
    "\n",
    "    #for value_change in pct_to_target1: # cycles through each value from MC range\n",
    "    for value_change in list_final:\n",
    "\n",
    "        # create and build model\n",
    "        m = wt.watertap_setup(dynamic = False)\n",
    "        m = wt.case_study_trains.get_case_study(name = 'carlsbad', flow = 4.5833, m = m)\n",
    "\n",
    "        getattr(m.fs, up_name).water_recovery.fix(value_change)\n",
    "\n",
    "        # set variable to MC value\n",
    "        result = wt.run_water_tap(m)\n",
    "        results_table = get_results_table(m, unit_process_names)\n",
    "        cost_range_list.append(results_table.total_up_cost.sum())\n",
    "\n",
    "\n",
    "    return cost_range_list\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "pool=Pool()\n",
    "dfs = pool.map(monte_run, list_final) #SomeClass().preprocess_data()\n",
    "\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####TO DO LOAD AND SAVE!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SAVE TRAIN ####\n",
    "# path = 'trains/Tutorial1_treatment_train_example.csv'\n",
    "# wt.save_train(T, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### LOAD TRAIN ####\n",
    "# path = 'trains/Tutorial1_treatment_train_example.csv'\n",
    "# TT = wt.load_train(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wt.display.show_train(TT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
