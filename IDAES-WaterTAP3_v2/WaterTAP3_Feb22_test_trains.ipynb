{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import watertap as wt\n",
    "import pandas as pd\n",
    "from pyomo.environ import value, Block\n",
    "from idaes.core import FlowsheetBlock\n",
    "%matplotlib inline\n",
    "from pylab import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from case_study_trains import *\n",
    "import case_study_trains\n",
    "# import pyomo.util.infeasible as infeas\n",
    "# print(infeas.log_infeasible_bounds(m))\n",
    "# infeas.log_close_to_bounds(m)\n",
    "\n",
    "\n",
    "m = wt.watertap_setup(dynamic = False)\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"KBHDP\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"Irwin\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"EMWD\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"Santa_Barbara\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"Carlsbad\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"Ashkelon\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"Tampa_Bay\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"HRSD\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"Big_Spring\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "wt.case_study_trains.train = {\"case_study\": \"OCWD\",\n",
    "                             \"reference\": \"NAWI\",\n",
    "                             \"scenario\": \"Baseline\"}\n",
    "\n",
    "# wt.case_study_trains.train = {\"case_study\": \"Solaire\",\n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\"}\n",
    "\n",
    "\n",
    "# TODO LATER: how to make this sync with info in train input data. We might not need to do that.\n",
    "#But, if the source water type is different to what is in the train (pfd dictionary), \n",
    "#then we should updat the node name. If more than two sources - what to do? Needs to be\n",
    "#based on pfd node!?\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"KBHDP\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"KBHDP_Brackish_Ave\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"Irwin\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"Brackish\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"EMWD\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"EMWD_CA_Brackish\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"Santa_Barbara\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"Seawater\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"Carlsbad\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"Seawater\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"Ashkelon\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"Seawater\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"Tampa_Bay\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"Seawater\"}\n",
    "# \n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"HRSD\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"HRSD_Municipal\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"Big_Spring\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"Big_Spring_Feed\"}\n",
    "\n",
    "wt.case_study_trains.source_water = {\"case_study\": \"OCWD\", \n",
    "                             \"reference\": \"NAWI\",\n",
    "                             \"scenario\": \"Baseline\",\n",
    "                             \"water_type\": \"OCWD_Feed\"}\n",
    "\n",
    "# wt.case_study_trains.source_water = {\"case_study\": \"Solaire\", \n",
    "#                              \"reference\": \"NAWI\",\n",
    "#                              \"scenario\": \"Baseline\",\n",
    "#                              \"water_type\": \"Solaire_Graywater\"}\n",
    "\n",
    "m = wt.case_study_trains.get_case_study(m=m) # flow is set as case study flow unless defined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wt.display.show_train2(model_name=m)\n",
    "# m.fs.pfd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def it_gets_results(appended, print_it=False, write_it=True):    \n",
    "    train = wt.case_study_trains.train\n",
    "\n",
    "    py_var = [\n",
    "        \"fixed_cap_inv\",\n",
    "        \"total_cap_investment\",\n",
    "        \"cat_and_chem_cost\",\n",
    "        \"electricity_cost\",\n",
    "        \"total_fixed_op_cost\",\n",
    "    \"flow_in\", \"flow_out\"]\n",
    "\n",
    "    excel_var = ['Fixed Capital Investment (FCI)',\n",
    "                'Total Capital Investment (TCI)',\n",
    "                'Catalysts and Chemicals',\n",
    "                'Electricity',\n",
    "                'Total Fixed Operating Costs']\n",
    "\n",
    "    case_study = train['case_study']\n",
    "    if print_it:\n",
    "        print(f'\\n######### Case study = {case_study} #########\\n\\n\\n')\n",
    "\n",
    "    cap_inv_tot = []\n",
    "\n",
    "    big_dict = {}\n",
    "\n",
    "    for b_unit in m.fs.component_objects(Block, descend_into=True):\n",
    "        unit = str(b_unit)[3:]\n",
    "        if hasattr(b_unit, 'costing'):\n",
    "            if print_it:\n",
    "                print(f'____________{unit}____________')\n",
    "            py_vals =  []\n",
    "            excel_vals = []\n",
    "            big_dict[unit] = {'python': {}, 'excel': {}}\n",
    "            df = pd.read_csv(\"data/case_study_results.csv\")\n",
    "            df = df[df.case_study == train['case_study']]\n",
    "            df = df[df.scenario == train['scenario']]\n",
    "            df = df[df.unit_process == unit]\n",
    "            flow_in_excel = round(df[df.variable == \"flow_vol_in\"].value.sum(), 5)\n",
    "            flow_out_excel = round(df[df.variable == 'flow_vol_out'].value.sum(), 5)\n",
    "            flow_in_python = round(value(b_unit.inlet.flow_vol[0.0] * 3600), 5)\n",
    "            flow_out_python = round(value(b_unit.outlet.flow_vol[0.0] * 3600), 5)\n",
    "            waste_python = round(value(b_unit.waste.flow_vol[0.0] * 3600), 5)\n",
    "            if print_it:\n",
    "                print(f'\\n#### flow_in\\nPython --> {flow_in_python}')\n",
    "                print(f'Excel --> {flow_in_excel}\\n\\n')\n",
    "                print(f'#### flow out\\nPython --> {flow_out_python}')\n",
    "                print(f'Excel --> {flow_out_excel}\\n\\n')\n",
    "                print(f'#### waste\\nPython--> {waste_python}\\n')\n",
    "            for py, ex in dict(zip(py_var, excel_var)).items():\n",
    "                if print_it:\n",
    "                    print(f'\\n#### {py}')\n",
    "                try:\n",
    "                    num = value(getattr(b_unit.costing, py))\n",
    "                    py_vals.append(num)\n",
    "                    if print_it:\n",
    "                        print(f'Python --> {round(num, 5)}')\n",
    "                except ZeroDivisionError:\n",
    "                    if print_it:\n",
    "                        print(f'Python --> {0} - ERROR')\n",
    "                    py_vals.append(0)\n",
    "\n",
    "                df = pd.read_csv(\"data/case_study_results.csv\")\n",
    "                df = df[df.case_study == train['case_study']]\n",
    "                df = df[df.scenario == train['scenario']]\n",
    "                df = df[df.unit_process == unit]\n",
    "                num = df[df.Variable == ex].value.sum()\n",
    "                if print_it:\n",
    "                    print(f'Excel --> {round(num, 5)}\\n\\n')\n",
    "                excel_vals.append(num)\n",
    "            py_vals.append(flow_in_python)\n",
    "            py_vals.append(flow_out_python)\n",
    "            py_dict = dict(zip(py_var, py_vals))\n",
    "            excel_vals.append(flow_in_excel)\n",
    "            excel_vals.append(flow_out_excel)\n",
    "            excel_dict = dict(zip(py_var, excel_vals))\n",
    "            big_dict[unit]['python'] = py_dict\n",
    "            big_dict[unit]['excel'] = excel_dict\n",
    "\n",
    "    else:\n",
    "        pass \n",
    "\n",
    "    df = pd.DataFrame.from_dict({(i,j): big_dict[i][j] \n",
    "                               for i in big_dict.keys() \n",
    "                               for j in big_dict[i].keys()},\n",
    "                               orient='index')\n",
    "\n",
    "    df['case_study'] = case_study\n",
    "    df['LCOW'] = value(m.fs.costing.LCOW)\n",
    "    if write_it:\n",
    "        df.to_csv(f'results/test_compare_{case_study}_{appended}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wt.run_water_tap(m=m, solver_results=True, print_model_results=False)\n",
    "# it_gets_results('testy1')\n",
    "# wt.run_water_tap(m=m, solver_results=True, print_model_results=False)\n",
    "# it_gets_results('testy2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_it_all(append1, append2, solver_results=True, model_results=False):\n",
    "    case_studies = ['Ashkelon', 'Big_Spring', 'Carlsbad', 'EMWD', 'HRSD', 'Irwin', 'KBHDP', 'OCWD', 'Santa_Barbara', 'Solaire', 'Tampa_Bay']\n",
    "    water_sources = ['Seawater', 'Big_Spring_Feed', 'Seawater', 'EMWD_CA_Brackish', 'HRSD_Municipal', 'Brackish', 'KBHDP_Brackish_Ave', 'OCWD_Feed', 'Seawater', 'Solaire_Graywater', 'Seawater']\n",
    "    wt_dict = dict(zip(case_studies, water_sources))\n",
    "    for k, v in wt_dict.items():\n",
    "        \n",
    "        m = wt.watertap_setup(dynamic = False)\n",
    "        \n",
    "        wt.case_study_trains.train = {\"case_study\": k,\n",
    "                                 \"reference\": \"NAWI\",\n",
    "                                 \"scenario\": \"Baseline\"}\n",
    "        \n",
    "        wt.case_study_trains.source_water = {\"case_study\": k, \n",
    "                                 \"reference\": \"NAWI\",\n",
    "                                 \"scenario\": \"Baseline\",\n",
    "                                 \"water_type\": v}\n",
    "        \n",
    "        wt.run_water_tap(m=m, solver_results=solver_results, print_model_results=model_results)\n",
    "        \n",
    "        it_gets_results(append1)\n",
    "        \n",
    "        wt.run_water_tap(m=m, solver_results=solver_results, print_model_results=model_results)\n",
    "        \n",
    "        it_gets_results(append2)\n",
    "# value(m.fs.costing.LCOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wt.run_water_tap(m=m, solver_results=True, print_model_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(f'results/test_compare_{case_study}.csv')\n",
    "wt.run_water_tap(m=m, solver_results=True, print_model_results=False)\n",
    "\n",
    "train = wt.case_study_trains.train\n",
    "\n",
    "py_var = [\n",
    "    \"fixed_cap_inv\",\n",
    "    \"total_cap_investment\",\n",
    "    \"cat_and_chem_cost\",\n",
    "    \"electricity_cost\",\n",
    "    \"total_fixed_op_cost\",\n",
    "\"flow_in\", \"flow_out\"]\n",
    "\n",
    "excel_var = ['Fixed Capital Investment (FCI)',\n",
    "            'Total Capital Investment (TCI)',\n",
    "            'Catalysts and Chemicals',\n",
    "            'Electricity',\n",
    "            'Total Fixed Operating Costs']\n",
    "\n",
    "case_study = train['case_study']\n",
    "print(f'\\n######### Case study = {case_study} #########\\n\\n\\n')\n",
    "\n",
    "cap_inv_tot = []\n",
    "\n",
    "big_dict = {}\n",
    "\n",
    "for b_unit in m.fs.component_objects(Block, descend_into=True):\n",
    "    unit = str(b_unit)[3:]\n",
    "    if hasattr(b_unit, 'costing'):\n",
    "        print(f'____________{unit}____________')\n",
    "        py_vals =  []\n",
    "        excel_vals = []\n",
    "        big_dict[unit] = {'python': {}, 'excel': {}}\n",
    "        df = pd.read_csv(\"data/case_study_results.csv\")\n",
    "        df = df[df.case_study == train['case_study']]\n",
    "        df = df[df.scenario == train['scenario']]\n",
    "        df = df[df.unit_process == unit]\n",
    "        flow_in_excel = round(df[df.variable == \"flow_vol_in\"].value.sum(), 5)\n",
    "        flow_out_excel = round(df[df.variable == 'flow_vol_out'].value.sum(), 5)\n",
    "        flow_in_python = round(value(b_unit.inlet.flow_vol[0.0] * 3600), 5)\n",
    "        flow_out_python = round(value(b_unit.outlet.flow_vol[0.0] * 3600), 5)\n",
    "        waste_python = round(value(b_unit.waste.flow_vol[0.0] * 3600), 5)\n",
    "        print(f'\\n#### flow_in\\nPython --> {flow_in_python}')\n",
    "        print(f'Excel --> {flow_in_excel}\\n\\n')\n",
    "        print(f'#### flow out\\nPython --> {flow_out_python}')\n",
    "        print(f'Excel --> {flow_out_excel}\\n\\n')\n",
    "        print(f'#### waste\\nPython--> {waste_python}\\n')\n",
    "        for py, ex in dict(zip(py_var, excel_var)).items():\n",
    "            print(f'\\n#### {py}')\n",
    "            try:\n",
    "                num = value(getattr(b_unit.costing, py))\n",
    "                py_vals.append(num)\n",
    "                print(f'Python --> {round(num, 5)}')\n",
    "            except ZeroDivisionError:\n",
    "                print(f'Python --> {0} - ERROR')\n",
    "                py_vals.append(0)\n",
    "            \n",
    "            df = pd.read_csv(\"data/case_study_results.csv\")\n",
    "            df = df[df.case_study == train['case_study']]\n",
    "            df = df[df.scenario == train['scenario']]\n",
    "            df = df[df.unit_process == unit]\n",
    "            num = df[df.Variable == ex].value.sum()\n",
    "            print(f'Excel --> {round(num, 5)}\\n\\n')\n",
    "            excel_vals.append(num)\n",
    "        py_vals.append(flow_in_python)\n",
    "        py_vals.append(flow_out_python)\n",
    "        py_dict = dict(zip(py_var, py_vals))\n",
    "        excel_vals.append(flow_in_excel)\n",
    "        excel_vals.append(flow_out_excel)\n",
    "        excel_dict = dict(zip(py_var, excel_vals))\n",
    "        big_dict[unit]['python'] = py_dict\n",
    "        big_dict[unit]['excel'] = excel_dict\n",
    "        \n",
    "else:\n",
    "    pass \n",
    "\n",
    "df = pd.DataFrame.from_dict({(i,j): big_dict[i][j] \n",
    "                           for i in big_dict.keys() \n",
    "                           for j in big_dict[i].keys()},\n",
    "                           orient='index')\n",
    "\n",
    "df['case_study'] = case_study\n",
    "df['LCOW'] = value(m.fs.costing.LCOW)\n",
    "df.to_csv(f'results/test_compare_{case_study}_new2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value(m.fs.costing.LCOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value(m.fs.coag_and_floc.water_recovery[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'results/test_compare_{case_study}_new1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_final = pd.DataFrame()\n",
    "# for case_name in [\"Ashkelon\", \"Carlsbad\", \"Tampa_Bay\"]: #, \"Santa_Barbra\"]: #, \"Ashkelon\"]:\n",
    "\n",
    "#     m = wt.watertap_setup(dynamic = False)\n",
    "\n",
    "#     wt.case_study_trains.train = {\"case_study\": case_name,\n",
    "#                                  \"reference\": \"NAWI\",\n",
    "#                                  \"scenario\": \"Baseline\"}\n",
    "\n",
    "#     # TODO LATER: how to make this sync with info in train input data. We might not need to do that.\n",
    "#     #But, if the source water type is different to what is in the train (pfd dictionary), \n",
    "#     #then we should updat the node name. If more than two sources - what to do? Needs to be\n",
    "#     #based on pfd node!?\n",
    "\n",
    "#     wt.case_study_trains.source_water = {\"case_study\": case_name, \n",
    "#                                  \"reference\": \"NAWI\",\n",
    "#                                  \"scenario\": \"Baseline\",\n",
    "#                                  \"water_type\": \"Seawater\"}\n",
    "    \n",
    "#     m = wt.case_study_trains.get_case_study(m = m) # flow is set as case study flow unless defined.\n",
    "    \n",
    "      \n",
    "#     wt.run_water_tap(m = m, solver_results = False, print_model_results = False)\n",
    "#     print(value(m.fs.costing.LCOW))\n",
    "#     df = get_results_table()\n",
    "#     df[\"case_study\"] = case_name\n",
    "#     df_final = pd.concat([df_final,df])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_table():\n",
    "\n",
    "    train = wt.case_study_trains.train\n",
    "\n",
    "    py_var = [\n",
    "        \"fixed_cap_inv\",\n",
    "        \"total_cap_investment\",\n",
    "        \"cat_and_chem_cost\",\n",
    "        \"electricity_cost\",\n",
    "        \"total_fixed_op_cost\"]\n",
    "\n",
    "    excel_var = ['Fixed Capital Investment (FCI)',\n",
    "                'Total Capital Investment (TCI)',\n",
    "                'Catalysts and Chemicals',\n",
    "                'Electricity',\n",
    "                'Total Fixed Operating Costs']\n",
    "    big_dict = {}\n",
    "    # for letter in ['A', 'B', 'C']:\n",
    "    for b_unit in m.fs.component_objects(Block, descend_into=True):\n",
    "        unit = str(b_unit)[3:]\n",
    "        if hasattr(b_unit, 'costing'):\n",
    "            #print(f'____________{unit}____________')\n",
    "            py_vals =  []\n",
    "            excel_vals = []\n",
    "            big_dict[unit] = {'python': {}, 'excel': {}}\n",
    "            for py, ex in dict(zip(py_var, excel_var)).items():\n",
    "                #print(f'\\n#### {py}')\n",
    "                try:\n",
    "                    num = value(getattr(b_unit.costing, py))\n",
    "                    py_vals.append(num)\n",
    "                    #print(f'Python --> {num}')\n",
    "                except ZeroDivisionError:\n",
    "                    #print(f'Python --> {0} - ERROR')\n",
    "                    py_vals.append(0)\n",
    "                py_dict = dict(zip(py_var, py_vals))\n",
    "                df = pd.read_csv(\"data/case_study_results.csv\")\n",
    "                df = df[df.case_study == train['case_study']]\n",
    "                df = df[df.scenario == train['scenario']]\n",
    "                df = df[df.unit_process == unit]\n",
    "                num = df[df.Variable == ex].value.max()\n",
    "                #print(f'Excel --> {num}\\n\\n')\n",
    "                excel_vals.append(num)\n",
    "                excel_dict = dict(zip(py_var, excel_vals))\n",
    "            big_dict[unit]['python'] = py_dict\n",
    "            big_dict[unit]['excel'] = excel_dict\n",
    "    else:\n",
    "        pass \n",
    "\n",
    "\n",
    "\n",
    "    df = pd.DataFrame.from_dict({(i,j): big_dict[i][j] \n",
    "                               for i in big_dict.keys() \n",
    "                               for j in big_dict[i].keys()},\n",
    "                           orient='index')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = case_study_trains.train \n",
    "source_water = case_study_trains.source_water \n",
    "source_or_use = None\n",
    "# getting the list of consituents with removal factors that are bigger than 0\n",
    "df1 = pd.read_csv(\"data/constituent_removal.csv\")\n",
    "df1 = df1[df1.reference == train[\"reference\"]]\n",
    "df1 = df1[df1.case_study == train[\"case_study\"]]\n",
    "df1 = df1[df1.scenario == train[\"scenario\"]]\n",
    "\n",
    "list1 = df1[df1.value >=0].constituent.unique()\n",
    "\n",
    "import importfile\n",
    "\n",
    "# grabs inlet water information\n",
    "# df = importfile.feedwater(\n",
    "#     input_file=\"data/case_study_water_sources.csv\",\n",
    "#     reference = source_water[\"reference\"], \n",
    "#     water_type = source_water[\"water_type\"], \n",
    "#     case_study = source_water[\"case_study\"],\n",
    "#     scenario = source_water[\"scenario\"])\n",
    "\n",
    "df2 = pd.read_csv('data/case_study_water_sources.csv', index_col='variable')\n",
    "df2 = df2[df2.reference == source_water['reference']]\n",
    "df2 = df2[df2.water_type == source_water['water_type']]\n",
    "df2 = df2[df2.case_study == source_water['case_study']]\n",
    "# df = df[df.source_or_use == source_water['source_or_use']]\n",
    "df2 = df2[df2.scenario == source_water['scenario']]\n",
    "df2 = df2.set_index(df2.index)\n",
    "df2['feedwater'] = df2.value\n",
    "df2['SourceNodeName'] = 'source_node'\n",
    "# gets list of consituents in inlet water\n",
    "list2 = df2.index\n",
    "\n",
    "# # combines list\n",
    "final_list = [x for x in list1 if x in list2]\n",
    "print(f'list1 = {list1}')\n",
    "print(f'list2 = {list2}')\n",
    "print(f'final_list = {final_list}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import case_study_trains\n",
    "unit_process = 'ro_deep'\n",
    "train = case_study_trains.train \n",
    "source_water = case_study_trains.source_water \n",
    "\n",
    "df = pd.read_csv(\"data/constituent_removal.csv\")\n",
    "df.case_study = np.where(df.case_study == \"Default\", train[\"case_study\"], df.case_study)\n",
    "df = df[df.reference == train[\"reference\"]]\n",
    "df = df[df.case_study == train[\"case_study\"]]\n",
    "df = df[df.scenario == train[\"scenario\"]]\n",
    "df = df[df.unit_process == unit_process]\n",
    "\n",
    "removal_dict = {}\n",
    "for constituent in df.constituent.unique():\n",
    "    removal_dict[constituent] = df[df.constituent == constituent].value.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removal_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generate_constituent_list\n",
    "df = pd.read_csv(\"data/water_recovery.csv\")\n",
    "case_study_name = case_study_trains.train[\"case_study\"]\n",
    "unit_process_type = 'microfiltration'\n",
    "unit_process_name = unit_process_type\n",
    "if unit_process_type == \"reverse_osmosis\": unit_process_type = \"ro_deep\"\n",
    "\n",
    "if case_study_name in df[df.unit_process == unit_process_type].case_study:\n",
    "    if \"calculated\" not in df[((df.unit_process == unit_process_type) & (df.case_study == case_study_name))].recovery.max():\n",
    "        flow_recovery_factor = float(df[((df.unit_process == unit_process_type) & (df.case_study == case_study_name))].recovery)\n",
    "        print(f'A = {flow_recovery_factor}\\n')\n",
    "        getattr(m.fs, unit_process_name).water_recovery.fix(flow_recovery_factor)\n",
    "else:\n",
    "    if \"calculated\" not in df[((df.unit_process == unit_process_type) & (df.case_study == \"Default\"))].recovery.max():\n",
    "        flow_recovery_factor = float(df[((df.unit_process == unit_process_type) & (df.case_study == \"Default\"))].recovery)\n",
    "        print(f'B = {flow_recovery_factor}\\n')\n",
    "        getattr(m.fs, unit_process_name).water_recovery.fix(flow_recovery_factor)\n",
    "\n",
    "# Get constituent list and removal rates for this unit process\n",
    "train_constituent_removal_factors = generate_constituent_list.get_removal_factors(unit_process_type)\n",
    "\n",
    "for constituent_name in getattr(m.fs, unit_process_name).config.property_package.component_list:\n",
    "    print(constituent_name)\n",
    "\n",
    "    if constituent_name in train_constituent_removal_factors.keys():\n",
    "        getattr(m.fs, unit_process_name).removal_fraction[:, constituent_name].fix(train_constituent_removal_factors[constituent_name])\n",
    "    else:\n",
    "        getattr(m.fs, unit_process_name).removal_fraction[:, constituent_name].fix(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value(m.fs.microfiltration.water_recovery[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_constituent_removal_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fs.microfiltration.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.unit_process == unit_process_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cost_range_list = []; #results will be inputted in this array\n",
    "#up_name = \"tri_media_filtration\" # which unit process it applies to. TODO hould be user input.\n",
    "\n",
    "#for value_change in pct_to_target1: # cycles through each value from MC range\n",
    "for value_change in [0.4, 0.8]: #, 0.9]:\n",
    "\n",
    "    # create and build model\n",
    "    m = wt.watertap_setup(dynamic = False)\n",
    "    m = wt.case_study_trains.get_case_study(name = 'carlsbad', flow = 4.5833, m = m)\n",
    "\n",
    "    m.fs.tri_media_filtration.water_recovery.fix(value_change)\n",
    "\n",
    "    # set variable to MC value\n",
    "    wt.run_water_tap(m)\n",
    "    results_table = get_results_table(m, unit_process_name)\n",
    "    cost_range_list.append(results_table.total_up_cost.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_range_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DO NOT USE THE BELOW ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "\n",
    "mu = 0.6\n",
    "sigma = .1\n",
    "num_reps = 50\n",
    "\n",
    "input_list = np.random.normal(mu,sigma, size = num_reps) #, sigma, num_reps).round(4)\n",
    "\n",
    "count, bins, ignored = plt.hist(input_list, 25, density=True)\n",
    "plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) * np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
    "          linewidth=2, color='r')\n",
    "plt.show()\n",
    "\n",
    "### INPUT TO MODEL LIST: ### CAN BE AUTOMATED FOR USER TO LABEL THE VARIABLE. TOOD ###\n",
    "no_of_proc = 4\n",
    "list_final = []\n",
    "for i in range(no_of_proc):\n",
    "    part2 = len(input_list) / no_of_proc\n",
    "    i2 = ((i+1)*part2)\n",
    "    list1 = input_list[int(i*part2):int(i2)]\n",
    "    list_final.append(list1)\n",
    "    \n",
    "    \n",
    "def monte_run(list_final):\n",
    "    print('goes in')\n",
    "\n",
    "    up_name = \"tri_media_filtration\" # which unit process it applies to. TODO hould be user input.\n",
    "    cost_range_list = []; #results will be inputted in this array\n",
    "\n",
    "    #for value_change in pct_to_target1: # cycles through each value from MC range\n",
    "    for value_change in list_final:\n",
    "\n",
    "        # create and build model\n",
    "        m = wt.watertap_setup(dynamic = False)\n",
    "        m = wt.case_study_trains.get_case_study(name = 'carlsbad', flow = 4.5833, m = m)\n",
    "\n",
    "        getattr(m.fs, up_name).water_recovery.fix(value_change)\n",
    "\n",
    "        # set variable to MC value\n",
    "        result = wt.run_water_tap(m)\n",
    "        results_table = get_results_table(m, unit_process_names)\n",
    "        cost_range_list.append(results_table.total_up_cost.sum())\n",
    "\n",
    "\n",
    "    return cost_range_list\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "pool=Pool()\n",
    "dfs = pool.map(monte_run, list_final) #SomeClass().preprocess_data()\n",
    "\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####TO DO LOAD AND SAVE!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SAVE TRAIN ####\n",
    "# path = 'trains/Tutorial1_treatment_train_example.csv'\n",
    "# wt.save_train(T, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### LOAD TRAIN ####\n",
    "# path = 'trains/Tutorial1_treatment_train_example.csv'\n",
    "# TT = wt.load_train(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wt.display.show_train(TT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
