{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook maps SDWIS, USGS GU and USGS model predictions data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'sdwis' includes data from 4 quarters. Dupicated for PWS ID, Facility ID and treatment process were dropped. Included facilities with Facility Activity Status = Active/Inactive\n",
    "\n",
    "USGS GUs are based on places- Has assigned PWS IDs/Seller PWS IDs and WSA IDs\n",
    "\n",
    "DPC has WSA \n",
    "\n",
    "Goal of this flow sheet is to map PWS ID from the SDWIS data set to the WSA ID using the USGS GU data set. Map the per capita consumption to the WSA ID using the DPC data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_latest_2 has sdwis data for all 4 quarters and drops duplicates\n",
    "PATH = r'C:\\Users\\mhardika\\Documents\\AMO\\2050\\analysis_files_2024'\n",
    "sdwis = pd.read_csv(PATH + '\\df_latest_2.csv',low_memory=False)\n",
    "# Reading the USGS v1_GU_wWS file and converting to a dataframe\n",
    "usgs_gu_wwsa = gp.read_file(PATH + r'\\V1_GU_wWS\\v1_GU_wWS.shp')\n",
    "usgs_gu_wwsa_df = pd.DataFrame(usgs_gu_wwsa.drop(columns='geometry'))\n",
    "\n",
    "# Reading Machine learning model output for domestic demand per capita and filtering for the year 2020\n",
    "dpc_2020 = pd.read_csv(PATH + r'\\delivery_water_use_model\\predictions\\national_dpc_predictions.csv')\n",
    "dpc_2020 = dpc_2020.loc[dpc_2020['year']==2020].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with duplicate PWS ID, Facility ID and treatment process\n",
    "sdwis_filtered = sdwis[['PWS ID','Facility Id','PWS Name', 'Population Served Count', \n",
    "                        'Activity Status', 'Facility Activity', 'Primary Source', 'PWS Type',\n",
    "                        'Treatment Process','Treatment Objective']].drop_duplicates(subset = ['PWS ID','Facility Id','Treatment Process'])\n",
    "\n",
    "# Remove rows without an treatment process listed\n",
    "sdwis_filtered = sdwis_filtered.dropna(subset=['Treatment Process'])\n",
    "# Remove PWS ID and Facility with only 1 treatment process\n",
    "# sdwis_filtered = sdwis_filtered.groupby(['PWS ID','Facility Id']).filter(lambda x: len(x['Treatment Process'])>1).reset_index()\n",
    "\n",
    "# Filter for where population served is 0\n",
    "# sdwis_filtered = sdwis_filtered[sdwis_filtered['Population Served Count']>0]\n",
    "# usgs_gu_wwsa_df  = usgs_gu_wwsa_df[usgs_gu_wwsa_df['GU_POP']>0]\n",
    "\n",
    "# Update the USGS DPC data to be upper case if it is alphanumeric\n",
    "updated_column_list = []\n",
    "avg_dpc = []\n",
    "\n",
    "for idx,row in dpc_2020.iterrows():\n",
    "    try:\n",
    "        a = int(row['wsa_agidf'])\n",
    "        updated_column_list.append(str(f'{a:09d}'))\n",
    "    except:\n",
    "        updated_column_list.append(row['wsa_agidf'].upper())\n",
    "\n",
    "    avg_dpc.append(row.iloc[5::].mean())\n",
    "\n",
    "dpc_2020['wsa_agidf'] = updated_column_list\n",
    "dpc_2020['avg_dpc'] = avg_dpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique PWS_ID in SDWIS filtered (df_latest_2): 53130\n",
      "\n",
      "USGS v1_GU-wWS\n",
      "Total USGS v1_GU-wWS rows: 27159\n",
      "Unique PWS_ID in USGS v1_GU-wWS: 21429\n",
      "Unique Seller PWS_ID in USGS v1_GU-wWS: 1706\n",
      "Total unique PWS IDs (with/without seller) in v1_USGS GU-wWS: 22252\n",
      "Unique WSA_AGIDF in USGS v1_GU-wWS: 18807\n",
      "\n",
      "USGS DPC data: 18807\n"
     ]
    }
   ],
   "source": [
    "# Get unique PWS IDs in SDWIS data set\n",
    "sdwis_pws_ids = sdwis_filtered['PWS ID'].unique()\n",
    "\n",
    "# Get unique PWS IDs/Seller PWS ID in USGS GU dataset \n",
    "usgs_pws_ids = usgs_gu_wwsa_df['PWS_ID'].unique()\n",
    "usgs_seller_pws_ids = usgs_gu_wwsa_df['SELLER_PWS'].dropna().unique()\n",
    "\n",
    "combined_pws_ids = np.unique(np.concatenate([usgs_seller_pws_ids,usgs_pws_ids]))\n",
    "# Get unique WSA ID in USGS GU dataset\n",
    "usgs_wsa_ids = usgs_gu_wwsa_df['WSA_AGIDF'].unique()\n",
    "# Get unique WSA ID in USGS DPC dataset\n",
    "dpc_wsa_ids = dpc_2020['wsa_agidf'].unique()\n",
    "\n",
    "print('Unique PWS_ID in SDWIS filtered (df_latest_2):', len(sdwis_pws_ids))\n",
    "\n",
    "\n",
    "print('\\nUSGS v1_GU-wWS')\n",
    "print('Total USGS v1_GU-wWS rows:',len(usgs_gu_wwsa_df))\n",
    "print('Unique PWS_ID in USGS v1_GU-wWS:', len(usgs_pws_ids))\n",
    "print('Unique Seller PWS_ID in USGS v1_GU-wWS:', len(usgs_seller_pws_ids))\n",
    "print('Total unique PWS IDs (with/without seller) in v1_USGS GU-wWS:', len(combined_pws_ids))\n",
    "print('Unique WSA_AGIDF in USGS v1_GU-wWS:', len(usgs_wsa_ids))\n",
    "print('\\nUSGS DPC data:', len(dpc_wsa_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In USGS v1_GU_wWs dataset but not USGS DPC: ['CO0118006', 'CA3610057', 'CO0203002']\n",
      "In USGS DPC dataset but not USGS v1_GU_wWs: ['CA2010009', 'CA3310018', 'CA3310025']\n"
     ]
    }
   ],
   "source": [
    "# Check if all the WSA IDs are the same between the USGS GU-wWS and USGS DPC dataset\n",
    "res_usgs_wsa_ids = [i for i in usgs_wsa_ids if i not in dpc_wsa_ids]\n",
    "res_dpc = [i for i in dpc_wsa_ids if i not in usgs_wsa_ids]\n",
    "\n",
    "print('In USGS v1_GU_wWs dataset but not USGS DPC:', res_usgs_wsa_ids)\n",
    "print('In USGS DPC dataset but not USGS v1_GU_wWs:', res_dpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to check if USGS v1_GU_wWs dataset PWS IDs can be mapped to SDWIS df_latest dataset\n",
    "\n",
    "usgs_check = usgs_gu_wwsa_df[['GU_ID','PLACE_FIPS','PLACE_NAME','CNTY_NM', 'STATE_NAME','PWS_ID','SELLER_PWS','WSA_AGIDF']].copy()\n",
    "\n",
    "# Check if the PWS ID or Seller PWS ID is in the SDWIS dataset\n",
    "check_list = []\n",
    "pws_check_list = []\n",
    "\n",
    "for idx,row in usgs_check.iterrows():\n",
    "    if row['SELLER_PWS'] in sdwis_pws_ids:\n",
    "        check_list.append('Yes')\n",
    "        pws_check_list.append(row['SELLER_PWS'])\n",
    "    elif row['PWS_ID'] in sdwis_pws_ids:\n",
    "        check_list.append('Yes')\n",
    "        pws_check_list.append(row['PWS_ID'])\n",
    "    elif row['WSA_AGIDF'] in sdwis_pws_ids:\n",
    "        check_list.append('Yes')\n",
    "        pws_check_list.append(row['WSA_AGIDF'])\n",
    "    else:\n",
    "        check_list.append('No')\n",
    "        pws_check_list.append(row['WSA_AGIDF'])\n",
    "\n",
    "usgs_check['pws_check'] = pws_check_list\n",
    "usgs_check['In SDWIS'] = check_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping usgs check pws_check to dpc 2020 population\n",
    "usgs_check_dpc = usgs_check.merge(dpc_2020[['wsa_agidf','avg_dpc']],left_on='WSA_AGIDF',right_on='wsa_agidf')\n",
    "# usgs_check_dpc.to_csv(r'C:\\Users\\mhardika\\Documents\\AMO\\2050\\analysis_files_2024\\usgs_check_dpc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USGS v1_GU_wWs PWS IDs total: 22252\n",
      "\n",
      "Number of rows in USGS v1_GU_wWs that were mapped to SDWIS: 25315\n",
      "Number of rows in USGS v1_GU_wWs that were NOT mapped to SDWIS: 1844\n",
      "Number of unique PWS IDs/WSA IDs of the ones that were mapped to the SDWIS: 18998\n",
      "Number of unique PWS IDs in USGS v1_GU_wWs not in SDWIS dataset: 3254\n",
      "\n",
      "Number of SDWIS PWS IDs not included in the USGS v1_GU_wWs dataset: 30878\n"
     ]
    }
   ],
   "source": [
    "print('USGS v1_GU_wWs PWS IDs total:', len(combined_pws_ids))\n",
    "\n",
    "print('\\nNumber of rows in USGS v1_GU_wWs that were mapped to SDWIS:', len(usgs_check[usgs_check['In SDWIS']=='Yes']))\n",
    "print('Number of rows in USGS v1_GU_wWs that were NOT mapped to SDWIS:', len(usgs_check[usgs_check['In SDWIS']=='No']))\n",
    "\n",
    "usgs_check_yes = usgs_check[usgs_check['In SDWIS']=='Yes'].copy()\n",
    "usgs_check_no = usgs_check[usgs_check['In SDWIS']=='No'].copy()\n",
    "print('Number of unique PWS IDs/WSA IDs of the ones that were mapped to SDWIS:',len(usgs_check['pws_check'].unique()))\n",
    "# print('Number of unique PWS IDs of the ones that were mapped to the SDWIS:',len(usgs_check_yes['pws_check'].unique()))\n",
    "print('Number of unique PWS IDs in USGS v1_GU_wWs not in SDWIS:',len(combined_pws_ids) - len(usgs_check['pws_check'].unique()) )\n",
    "\n",
    "print('\\nNumber of SDWIS PWS IDs not included in the USGS v1_GU_wWs dataset:',len(sdwis_pws_ids)-len(combined_pws_ids) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking USDA DPC vs USGS DPC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filtered for Treatment and include Facility Activity = Activity/Inactive\n",
    "# sdwis_nofilter = pd.read_csv(r'C:\\Users\\mhardika\\Documents\\AMO\\2050\\analysis_files_2024\\SDWIS.csv',low_memory=False)\n",
    "# sdwis_facilities_nofilter = pd.read_csv(r'C:\\Users\\mhardika\\Documents\\AMO\\2050\\analysis_files_2024\\2020_WT_Facilities_Details.csv',low_memory=False)\n",
    "\n",
    "# Filter for Facility activity = Active\n",
    "# sdwis_filtered = sdwis_filtered[sdwis_filtered['Facility Activity']=='Active']\n",
    "\n",
    "# sdwis_no_filter_pws_ids = sdwis_nofilter['PWS ID'].unique()\n",
    "# sdwis_facilities_nofilter_pws_ids = sdwis_facilities_nofilter['PWS ID'].unique()\n",
    "# print('Unique PWS_ID in SDWIS no filter:', len(sdwis_no_filter_pws_ids))\n",
    "# print('Unique PWS_ID in SDWIS facilities no filter:', len(sdwis_facilities_nofilter_pws_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to check if USGS WSA data set PWS IDs can be mapped to SDWIS No filter dataset\n",
    "\n",
    "# usgs_check = usgs_gu_wwsa_df[['GU_ID','STATE_NAME','CNTY_NM','PLACE_FIPS','PLACE_NAME',\n",
    "#                               'GU_POP','WTR_TYPE_E','PWS_ID','SELLER_PWS','WSA_AGIDF']]\n",
    "\n",
    "# # Check if the PWS ID or Seller PWS ID is in the SDWIS dataset\n",
    "# check_list = []\n",
    "# pws_check_list = []\n",
    "\n",
    "# for idx,row in usgs_check.iterrows():\n",
    "#     if row['SELLER_PWS'] in sdwis_no_filter_pws_ids:\n",
    "#         check_list.append('Yes')\n",
    "#         pws_check_list.append(row['SELLER_PWS'])\n",
    "#     elif row['PWS_ID'] in sdwis_no_filter_pws_ids:\n",
    "#         check_list.append('Yes')\n",
    "#         pws_check_list.append(row['PWS_ID'])\n",
    "#     elif row['WSA_AGIDF'] in sdwis_no_filter_pws_ids:\n",
    "#         check_list.append('Yes')\n",
    "#         pws_check_list.append(row['WSA_AGIDF'])\n",
    "#     else:\n",
    "#         check_list.append('No')\n",
    "#         pws_check_list.append(row['WSA_AGIDF'])\n",
    "\n",
    "# usgs_check['pws_check'] = pws_check_list\n",
    "# usgs_check['In SDWIS'] = check_list\n",
    "\n",
    "# print('Number of facilities mapped to SDWIS no filter:', len(usgs_check[usgs_check['In SDWIS']=='Yes']))\n",
    "# print('Number of unique PWS IDs:',len(usgs_check['pws_check'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to check if USGS WSA data set PWS IDs can be mapped to SDWIS Facilities no filter dataset\n",
    "\n",
    "# usgs_check = usgs_gu_wwsa_df[['GU_ID','PLACE_FIPS','PLACE_NAME','CNTY_NM', 'STATE_NAME','PWS_ID','SELLER_PWS','WSA_AGIDF']]\n",
    "\n",
    "# # Check if the PWS ID or Seller PWS ID is in the SDWIS dataset\n",
    "# check_list = []\n",
    "# pws_check_list = []\n",
    "\n",
    "# for idx,row in usgs_check.iterrows():\n",
    "#     if row['SELLER_PWS'] in sdwis_facilities_nofilter_pws_ids:\n",
    "#         check_list.append('Yes')\n",
    "#         pws_check_list.append(row['SELLER_PWS'])\n",
    "#     elif row['PWS_ID'] in sdwis_facilities_nofilter_pws_ids:\n",
    "#         check_list.append('Yes')\n",
    "#         pws_check_list.append(row['PWS_ID'])\n",
    "#     elif row['WSA_AGIDF'] in sdwis_facilities_nofilter_pws_ids:\n",
    "#         check_list.append('Yes')\n",
    "#         pws_check_list.append(row['WSA_AGIDF'])\n",
    "#     else:\n",
    "#         check_list.append('No')\n",
    "#         pws_check_list.append(row['WSA_AGIDF'])\n",
    "\n",
    "# usgs_check['pws_check'] = pws_check_list\n",
    "# usgs_check['In SDWIS'] = check_list\n",
    "\n",
    "# print('Number of facilities mapped to SDWIS no filter:', len(usgs_check[usgs_check['In SDWIS']=='Yes']))\n",
    "# print('Number of unique PWS IDs:',len(usgs_check['pws_check'].unique()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watertap3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
